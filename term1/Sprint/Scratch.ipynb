{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target[50:]\n",
    "y.shape\n",
    "X = iris.data[50:]\n",
    "X.shape\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Radam():\n",
    "\n",
    "    def __init__(self, num_iter=5000, lr=0.05, bias=False, verbose=True,lamda=0.001):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.lam = lamda\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "    #シグモイド関数\n",
    "    def _rogistic_hypothesis(self,X): \n",
    "        return np.dot(X,self.coef_.T) \n",
    "    def sigmoid2(self,z):\n",
    "        \n",
    "        return 1/(1 + np.exp(-z))\n",
    "    #損失計算\n",
    "    def loss_logi2(self,h,y):\n",
    "        loss = np.sum((-y*np.log(h))-((1-y)*np.log(1-h)))/len(y) + (self.lam * np.sum(self.coef_**2)/len(y))\n",
    "        return loss\n",
    "    # 最急降下法\n",
    "    def _gradient_descent2(self,X,error):\n",
    "\n",
    "\n",
    "        #θ0あり\n",
    "        if self.bias ==True:\n",
    "            gradient1 = np.dot(error.T,X[:,0:1])/len(X)\n",
    "            gradient2 = np.dot(error.T,X[:,1:])/len(X)+(self.lam*self.coef_[:,1:]/X.shape[0])\n",
    "            #print(self.coef_)\n",
    "            self.coef_[:,0:1] -= self.lr * gradient1\n",
    "            #print(self.coef_)\n",
    "            self.coef_[:,1:] -= self.lr * gradient2\n",
    "            #print(self.coef_)\n",
    "        #θ0なし\n",
    "        else:\n",
    "            gradient = np.dot(error.T,X)/len(X)+(self.lam*self.coef_/X.shape[0])\n",
    "            self.coef_ -= self.lr * gradient\n",
    "            \n",
    "        return self.coef_\n",
    "\n",
    "               \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "\n",
    "        #Xにバイアスを追加\n",
    "        if self.bias ==True:\n",
    "            X = np.insert(X, 0, 1, axis=1)\n",
    "            if X_val is not None:\n",
    "                X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "                \n",
    "        #yを一列に変換\n",
    "        y = y[:,np.newaxis]\n",
    "        y = y-1\n",
    "        if y_val is not None:\n",
    "            y_val = y_val[:,np.newaxis]\n",
    "            y_val = y_val -1\n",
    "        #重みをランダムで生成\n",
    "        np.random.seed(seed=71)\n",
    "        self.coef_ = np.random.rand(1,X.shape[1]) \n",
    "        #print(self.coef_.shape)\n",
    "        for ite in range(self.iter):\n",
    "            #sigmoid\n",
    "            z = self._rogistic_hypothesis(X)\n",
    "            y_hat = self.sigmoid2(z)\n",
    "            #損失計算\n",
    "            lost = self.loss_logi2(y_hat, y)\n",
    "\n",
    "            #print(lost)\n",
    "            #格納\n",
    "            self.loss[ite] += lost\n",
    "\n",
    "            #error\n",
    "            error = y_hat - y\n",
    "            #print(y_hat.shape)\n",
    "            #theta の更新\n",
    "            self.coef_ = self._gradient_descent2(X,error)\n",
    "            \n",
    "            #検証None判定用\n",
    "            if y_val is not None:\n",
    "                #推定\n",
    "                z_val = self._rogistic_hypothesis(X_val)\n",
    "                y_hat_val = self.sigmoid2(z_val)\n",
    "                #損失\n",
    "                lost_val = self.loss_logi2(y_hat_val, y_val)\n",
    "                #格納\n",
    "                self.val_loss[ite] += lost_val\n",
    "\n",
    "        \n",
    "        \n",
    "        if self.verbose == True:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print(\"loss値{}\".format(self.loss))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        threshold = 0.5\n",
    "        pred = np.where((self.predict_proba(X))>= threshold,2,1)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        if self.bias ==True:\n",
    "            X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        #y_predict = np.dot(X,self.coef_ .T) \n",
    "        z = self._rogistic_hypothesis(X)\n",
    "\n",
    "        return self.sigmoid2(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss値[0.410581   0.40830098 0.40605082 ... 0.05734834 0.05734485 0.05734135]\n"
     ]
    }
   ],
   "source": [
    "sr = ScratchLogisticRegression(bias=True)\n",
    "sr.fit(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graff(loss,val_loss):\n",
    "    plt.plot(range(len(loss)),loss,label=\"train_loss\")\n",
    "    plt.plot(range(len(val_loss)),val_loss,label=\"test_loss\")\n",
    "    plt.legend()\n",
    "#    plt.ylim(0,30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graff(sr.loss,sr.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam (出典：http://arxiv.org/abs/1412.6980v8)\n",
    "class Adam:\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n",
    "        \n",
    "        for key in params.keys():\n",
    "            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n",
    "            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n",
    "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
    "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
    "            \n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n",
    "            \n",
    "            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\n",
    "            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\n",
    "            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamの実装\n",
    "class Adam2():\n",
    "\n",
    "    # インスタンス変数を定義\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr # 学習率\n",
    "        self.beta1 = beta1 # mの減衰率\n",
    "        self.beta2 = beta2 # vの減衰率\n",
    "        self.iter = 0 # 試行回数を初期化\n",
    "        self.m = None # モーメンタム\n",
    "        self.v = None # 適合的な学習係数\n",
    "    \n",
    "    # パラメータの更新メソッドを定義\n",
    "    def update(self, params, grads):\n",
    "        # mとvを初期化\n",
    "        if self.m is None: # 初回のみ\n",
    "            self.m = {}\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val) # 全ての要素が0\n",
    "                self.v[key] = np.zeros_like(val) # 全ての要素が0\n",
    "        \n",
    "        # パラメータごとに値を更新\n",
    "        self.iter += 1 # 更新回数をカウント\n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter) # 式(6)の学習率の項\n",
    "        for key in params.keys():\n",
    "            self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key] # 式(1)\n",
    "            self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * (grads[key] ** 2) # 式(2)\n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7) # 式(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import math\n",
    "#from itertools import izip\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "\n",
    "class Adam3():\n",
    "    def __init__(self,loss_type='log', alpha=0.001, beta1=0.9, beta2=0.999, epsilon=10**(-8)):\n",
    "        self.weight = np.zeros(feat_dim)  # features weight\n",
    "        self.loss_type = loss_type  # type of loss function\n",
    "        self.feat_dim = feat_dim  # number of dimension\n",
    "        self.x = np.zeros(feat_dim)  # feature\n",
    "        self.m = np.zeros(feat_dim)  # 1st moment vector\n",
    "        self.v = np.zeros(feat_dim)  # 2nd moment vector\n",
    "        self.alpha = alpha  # step size\n",
    "        self.beta1 = beta1  # Exponential decay rates for moment estimates\n",
    "        self.beta2 = beta2  # Exponential decay rates for moment estimates\n",
    "        self.epsilon = epsilon\n",
    "        self.t = 1  # timestep\n",
    "\n",
    "    def fit(self, data_fname, label_fname):\n",
    "        with open(data_fname, 'r') as f_data, open(label_fname, 'r') as f_label:\n",
    "            for data, label in izip(f_data, f_label):\n",
    "                self.features = np.array(data.rstrip().split(','), dtype=np.float64)\n",
    "                y = int(-1) if int(label.rstrip())<=0 else int(1)  # posi=1, nega=-1に統一\n",
    "                # update weight\n",
    "                self.update(self.predict(self.features), y)\n",
    "                self.t += 1\n",
    "        return self.weight\n",
    "\n",
    "    def predict(self, features): #margin\n",
    "        return np.dot(self.weight, features)\n",
    "\n",
    "    def calc_loss(self,m): # m=py=wxy\n",
    "        if self.loss_type == 'hinge':\n",
    "            return max(0,1-m)\n",
    "        elif self.loss_type == 'log':\n",
    "            # if m<=-700: m=-700\n",
    "            return math.log(1+math.exp(-m))\n",
    "\n",
    "    # gradient of loss function\n",
    "    def calc_dloss(self,m): # m=py=wxy\n",
    "        if self.loss_type == 'hinge':\n",
    "            res = -1.0 if (1-m)>0 else 0.0 # lossが0を超えていなければloss=0.そうでなければ-mの微分で-1になる\n",
    "            return res\n",
    "        elif self.loss_type == 'log':\n",
    "            if m < 0.0:\n",
    "                return float(-1.0) / (math.exp(m) + 1.0) # yx-e^(-m)/(1+e^(-m))*yx\n",
    "            else:\n",
    "                ez = float( math.exp(-m) )\n",
    "                return -ez / (ez + 1.0) # -yx+1/(1+e^(-m))*yx\n",
    "\n",
    "    def update(self, pred, y):\n",
    "        grad = y*self.calc_dloss(y*pred)*self.features  # gradient\n",
    "        self.m = self.beta1*self.m + (1 - self.beta1)*grad  # update biased first moment estimate\n",
    "        self.v = self.beta2*self.v + (1 - self.beta2)*grad**2  # update biased second raw moment estimate\n",
    "        mhat = self.m/(1-self.beta1**self.t)  # compute bias-corrected first moment estimate\n",
    "        vhat = self.v/(1-self.beta2**self.t)  # compute bias-corrected second raw moment estimate\n",
    "        self.alpha *= np.sqrt(1-self.beta2**self.t)/(1-self.beta1**self.t)  # update stepsize\n",
    "        self.weight -= self.alpha * mhat/(np.sqrt(vhat) + self.epsilon)  # update weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self,num_iter=1000, feat_dim=2, loss_type='log', alpha=0.001, beta1=0.9, beta2=0.999, epsilon=10**(-8),lamda=0.3,lr=0.01,bias=True,verbose=True):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.lam = lamda\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.weight = np.zeros(feat_dim)  # features weight\n",
    "        self.loss_type = loss_type  # type of loss function\n",
    "        self.feat_dim = feat_dim  # number of dimension\n",
    "        self.x = np.zeros(feat_dim)  # feature\n",
    "        self.m = np.zeros(feat_dim)  # 1st moment vector\n",
    "        self.v = np.zeros(feat_dim)  # 2nd moment vector\n",
    "        self.alpha = alpha  # step size\n",
    "        self.beta1 = beta1  # Exponential decay rates for moment estimates\n",
    "        self.beta2 = beta2  # Exponential decay rates for moment estimates\n",
    "        self.epsilon = epsilon\n",
    "        self.t = 1  # timestep\n",
    "\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        #シグモイド関数\n",
    "    def _rogistic_hypothesis(self,X): \n",
    "        return np.dot(X,self.coef_.T) \n",
    "    def sigmoid2(self,z):\n",
    "        \n",
    "        return 1/(1 + np.exp(-z))\n",
    "    #損失計算\n",
    "    def loss_logi2(self,h,y):\n",
    "        loss = np.sum((-y*np.log(h))-((1-y)*np.log(1-h)))/len(y) + (self.lam * np.sum(self.coef_**2)/len(y))\n",
    "        return loss\n",
    "\n",
    "    def update(self, pred, y):\n",
    "        grad = y*self.calc_dloss(y*pred)*self.features  # gradient\n",
    "        self.m = self.beta1*self.m + (1 - self.beta1)*grad  # update biased first moment estimate\n",
    "        self.v = self.beta2*self.v + (1 - self.beta2)*grad**2  # update biased second raw moment estimate\n",
    "        mhat = self.m/(1-self.beta1**self.t)  # compute bias-corrected first moment estimate\n",
    "        vhat = self.v/(1-self.beta2**self.t)  # compute bias-corrected second raw moment estimate\n",
    "        self.alpha *= np.sqrt(1-self.beta2**self.t)/(1-self.beta1**self.t)  # update stepsize\n",
    "        self.weight -= self.alpha * mhat/(np.sqrt(vhat) + self.epsilon)  # update weight\n",
    "        \n",
    "    def calc_dloss(self,m): # m=py=wxy\n",
    "        if self.loss_type == 'hinge':\n",
    "            res = -1.0 if (1-m)>0 else 0.0 # lossが0を超えていなければloss=0.そうでなければ-mの微分で-1になる\n",
    "            return res\n",
    "        elif self.loss_type == 'log':\n",
    "            if m < 0.0:\n",
    "                return float(-1.0) / (math.exp(m) + 1.0) # yx-e^(-m)/(1+e^(-m))*yx\n",
    "            else:\n",
    "                ez = float( math.exp(-m) )\n",
    "                return -ez / (ez + 1.0) # -yx+1/(1+e^(-m))*yx\n",
    "\n",
    "    def _gradient_descent2(self,X,error):\n",
    "\n",
    "\n",
    "        #θ0あり\n",
    "        if self.bias ==True:\n",
    "            gradient1 = np.dot(error.T,X[:,0:1])/len(X)\n",
    "            gradient2 = np.dot(error.T,X[:,1:])/len(X)+(self.lam*self.coef_[:,1:]/X.shape[0])\n",
    "            #print(self.coef_)\n",
    "            self.coef_[:,0:1] -= self.lr * gradient1\n",
    "            #print(self.coef_)\n",
    "            self.coef_[:,1:] -= self.lr * gradient2\n",
    "            #print(self.coef_)\n",
    "        #θ0なし\n",
    "        else:\n",
    "            gradient = np.dot(error.T,X)/len(X)+(self.lam*self.coef_/X.shape[0])\n",
    "            self.coef_ -= self.lr * gradient\n",
    "            \n",
    "        return self.coef_\n",
    "\n",
    "               \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "\n",
    "        #Xにバイアスを追加\n",
    "        if self.bias ==True:\n",
    "            X = np.insert(X, 0, 1, axis=1)\n",
    "            if X_val is not None:\n",
    "                X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "                \n",
    "        #yを一列に変換\n",
    "        y = y[:,np.newaxis]\n",
    "        y = y-1\n",
    "        if y_val is not None:\n",
    "            y_val = y_val[:,np.newaxis]\n",
    "            y_val = y_val -1\n",
    "        #重みをランダムで生成\n",
    "        np.random.seed(seed=71)\n",
    "        self.coef_ = np.random.rand(1,X.shape[1]) \n",
    "        #print(self.coef_.shape)\n",
    "        for ite in range(self.iter):\n",
    "            #sigmoid\n",
    "            z = self._rogistic_hypothesis(X)\n",
    "            y_hat = self.sigmoid2(z)\n",
    "            #損失計算\n",
    "            lost = self.loss_logi2(y_hat, y)\n",
    "\n",
    "            #print(lost)\n",
    "            #格納\n",
    "            self.loss[ite] += lost\n",
    "\n",
    "            #error\n",
    "            error = y_hat - y\n",
    "            #print(y_hat.shape)\n",
    "            #theta の更新\n",
    "            self.coef_ = self._gradient_descent2(X,error)\n",
    "            \n",
    "            #検証None判定用\n",
    "            if y_val is not None:\n",
    "                #推定\n",
    "                z_val = self._rogistic_hypothesis(X_val)\n",
    "                y_hat_val = self.sigmoid2(z_val)\n",
    "                #損失\n",
    "                lost_val = self.loss_logi2(y_hat_val, y_val)\n",
    "                #格納\n",
    "                self.val_loss[ite] += lost_val\n",
    "\n",
    "        \n",
    "        \n",
    "        if self.verbose == True:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "            print(\"loss値{}\".format(self.loss))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        threshold = 0.5\n",
    "        pred = np.where((self.predict_proba(X))>= threshold,2,1)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        if self.bias ==True:\n",
    "            X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "        #y_predict = np.dot(X,self.coef_ .T) \n",
    "        z = self._rogistic_hypothesis(X)\n",
    "\n",
    "        return self.sigmoid2(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss値[0.41757962 0.41712739 0.41667638 0.41622659 0.41577801 0.41533063\n",
      " 0.41488445 0.41443946 0.41399567 0.41355305 0.41311161 0.41267135\n",
      " 0.41223225 0.41179431 0.41135754 0.41092191 0.41048743 0.41005409\n",
      " 0.40962189 0.40919082 0.40876088 0.40833206 0.40790436 0.40747777\n",
      " 0.40705229 0.40662791 0.40620463 0.40578245 0.40536135 0.40494134\n",
      " 0.40452241 0.40410455 0.40368777 0.40327205 0.40285739 0.40244379\n",
      " 0.40203125 0.40161975 0.4012093  0.40079988 0.40039151 0.39998416\n",
      " 0.39957784 0.39917255 0.39876827 0.39836501 0.39796276 0.39756152\n",
      " 0.39716128 0.39676203 0.39636379 0.39596653 0.39557026 0.39517497\n",
      " 0.39478066 0.39438732 0.39399496 0.39360356 0.39321313 0.39282365\n",
      " 0.39243513 0.39204757 0.39166095 0.39127527 0.39089054 0.39050674\n",
      " 0.39012388 0.38974194 0.38936093 0.38898085 0.38860168 0.38822343\n",
      " 0.38784609 0.38746966 0.38709414 0.38671951 0.38634579 0.38597295\n",
      " 0.38560102 0.38522996 0.3848598  0.38449051 0.3841221  0.38375457\n",
      " 0.38338791 0.38302212 0.38265719 0.38229312 0.38192991 0.38156756\n",
      " 0.38120606 0.38084541 0.3804856  0.38012664 0.37976852 0.37941123\n",
      " 0.37905478 0.37869915 0.37834436 0.37799039 0.37763724 0.37728491\n",
      " 0.3769334  0.3765827  0.3762328  0.37588372 0.37553544 0.37518796\n",
      " 0.37484128 0.37449539 0.3741503  0.373806   0.37346248 0.37311975\n",
      " 0.3727778  0.37243663 0.37209623 0.37175661 0.37141776 0.37107967\n",
      " 0.37074235 0.3704058  0.37007    0.36973496 0.36940068 0.36906715\n",
      " 0.36873437 0.36840233 0.36807104 0.36774049 0.36741068 0.36708161\n",
      " 0.36675327 0.36642567 0.36609879 0.36577264 0.36544721 0.36512251\n",
      " 0.36479852 0.36447526 0.3641527  0.36383086 0.36350973 0.36318931\n",
      " 0.36286959 0.36255058 0.36223227 0.36191465 0.36159773 0.3612815\n",
      " 0.36096597 0.36065112 0.36033697 0.36002349 0.3597107  0.35939859\n",
      " 0.35908715 0.3587764  0.35846631 0.3581569  0.35784816 0.35754008\n",
      " 0.35723267 0.35692592 0.35661983 0.3563144  0.35600962 0.3557055\n",
      " 0.35540204 0.35509922 0.35479705 0.35449553 0.35419465 0.35389441\n",
      " 0.35359481 0.35329585 0.35299753 0.35269984 0.35240278 0.35210635\n",
      " 0.35181055 0.35151538 0.35122082 0.3509269  0.35063359 0.3503409\n",
      " 0.35004882 0.34975736 0.34946652 0.34917628 0.34888665 0.34859763\n",
      " 0.34830921 0.3480214  0.34773419 0.34744758 0.34716156 0.34687614\n",
      " 0.34659132 0.34630709 0.34602345 0.34574039 0.34545792 0.34517604\n",
      " 0.34489474 0.34461403 0.34433389 0.34405433 0.34377535 0.34349694\n",
      " 0.34321911 0.34294184 0.34266515 0.34238902 0.34211346 0.34183846\n",
      " 0.34156403 0.34129016 0.34101684 0.34074409 0.34047189 0.34020025\n",
      " 0.33992915 0.33965861 0.33938862 0.33911918 0.33885028 0.33858193\n",
      " 0.33831413 0.33804686 0.33778013 0.33751395 0.33724829 0.33698318\n",
      " 0.3367186  0.33645455 0.33619103 0.33592804 0.33566558 0.33540365\n",
      " 0.33514224 0.33488135 0.33462099 0.33436114 0.33410182 0.33384301\n",
      " 0.33358472 0.33332694 0.33306968 0.33281292 0.33255668 0.33230095\n",
      " 0.33204572 0.331791   0.33153678 0.33128307 0.33102985 0.33077714\n",
      " 0.33052493 0.33027321 0.33002199 0.32977127 0.32952103 0.32927129\n",
      " 0.32902204 0.32877328 0.32852501 0.32827722 0.32802992 0.32778311\n",
      " 0.32753677 0.32729092 0.32704554 0.32680065 0.32655623 0.32631229\n",
      " 0.32606882 0.32582582 0.3255833  0.32534125 0.32509967 0.32485855\n",
      " 0.3246179  0.32437772 0.324138   0.32389875 0.32365996 0.32342163\n",
      " 0.32318375 0.32294634 0.32270938 0.32247288 0.32223683 0.32200124\n",
      " 0.3217661  0.32153141 0.32129717 0.32106337 0.32083003 0.32059713\n",
      " 0.32036467 0.32013266 0.31990109 0.31966997 0.31943928 0.31920903\n",
      " 0.31897922 0.31874985 0.31852091 0.31829241 0.31806434 0.3178367\n",
      " 0.3176095  0.31738272 0.31715637 0.31693045 0.31670496 0.31647989\n",
      " 0.31625525 0.31603103 0.31580723 0.31558385 0.3153609  0.31513836\n",
      " 0.31491624 0.31469453 0.31447325 0.31425237 0.31403191 0.31381186\n",
      " 0.31359223 0.313373   0.31315419 0.31293578 0.31271778 0.31250018\n",
      " 0.31228299 0.31206621 0.31184983 0.31163384 0.31141827 0.31120309\n",
      " 0.31098831 0.31077392 0.31055994 0.31034635 0.31013315 0.30992035\n",
      " 0.30970795 0.30949593 0.30928431 0.30907307 0.30886223 0.30865177\n",
      " 0.3084417  0.30823202 0.30802272 0.3078138  0.30760527 0.30739712\n",
      " 0.30718936 0.30698197 0.30677496 0.30656833 0.30636208 0.30615621\n",
      " 0.30595071 0.30574558 0.30554083 0.30533645 0.30513245 0.30492881\n",
      " 0.30472555 0.30452266 0.30432013 0.30411797 0.30391618 0.30371475\n",
      " 0.30351369 0.30331299 0.30311266 0.30291268 0.30271307 0.30251382\n",
      " 0.30231493 0.3021164  0.30191822 0.3017204  0.30152294 0.30132583\n",
      " 0.30112908 0.30093268 0.30073663 0.30054094 0.30034559 0.3001506\n",
      " 0.29995595 0.29976165 0.2995677  0.2993741  0.29918085 0.29898793\n",
      " 0.29879537 0.29860314 0.29841126 0.29821972 0.29802852 0.29783766\n",
      " 0.29764714 0.29745696 0.29726712 0.29707761 0.29688844 0.29669961\n",
      " 0.2965111  0.29632294 0.2961351  0.2959476  0.29576043 0.29557359\n",
      " 0.29538708 0.2952009  0.29501505 0.29482952 0.29464432 0.29445945\n",
      " 0.2942749  0.29409068 0.29390678 0.2937232  0.29353995 0.29335701\n",
      " 0.2931744  0.29299211 0.29281013 0.29262848 0.29244714 0.29226612\n",
      " 0.29208542 0.29190503 0.29172495 0.29154519 0.29136574 0.29118661\n",
      " 0.29100779 0.29082927 0.29065107 0.29047318 0.2902956  0.29011832\n",
      " 0.28994136 0.2897647  0.28958834 0.28941229 0.28923655 0.28906111\n",
      " 0.28888597 0.28871114 0.28853661 0.28836238 0.28818845 0.28801482\n",
      " 0.28784148 0.28766845 0.28749572 0.28732328 0.28715114 0.28697929\n",
      " 0.28680774 0.28663648 0.28646552 0.28629485 0.28612448 0.28595439\n",
      " 0.2857846  0.28561509 0.28544588 0.28527696 0.28510832 0.28493997\n",
      " 0.28477191 0.28460414 0.28443665 0.28426945 0.28410253 0.28393589\n",
      " 0.28376954 0.28360348 0.28343769 0.28327219 0.28310696 0.28294202\n",
      " 0.28277735 0.28261297 0.28244886 0.28228503 0.28212148 0.28195821\n",
      " 0.28179521 0.28163248 0.28147004 0.28130786 0.28114596 0.28098433\n",
      " 0.28082297 0.28066189 0.28050107 0.28034053 0.28018026 0.28002025\n",
      " 0.27986052 0.27970105 0.27954185 0.27938291 0.27922425 0.27906585\n",
      " 0.27890771 0.27874984 0.27859223 0.27843489 0.27827781 0.27812099\n",
      " 0.27796443 0.27780813 0.2776521  0.27749632 0.2773408  0.27718555\n",
      " 0.27703055 0.27687581 0.27672132 0.27656709 0.27641312 0.2762594\n",
      " 0.27610594 0.27595274 0.27579978 0.27564708 0.27549463 0.27534244\n",
      " 0.2751905  0.2750388  0.27488736 0.27473617 0.27458523 0.27443453\n",
      " 0.27428409 0.27413389 0.27398394 0.27383424 0.27368478 0.27353557\n",
      " 0.27338661 0.27323789 0.27308941 0.27294118 0.27279318 0.27264544\n",
      " 0.27249793 0.27235067 0.27220365 0.27205686 0.27191032 0.27176402\n",
      " 0.27161795 0.27147213 0.27132654 0.27118119 0.27103608 0.2708912\n",
      " 0.27074656 0.27060216 0.27045799 0.27031405 0.27017035 0.27002689\n",
      " 0.26988365 0.26974065 0.26959788 0.26945534 0.26931303 0.26917096\n",
      " 0.26902911 0.26888749 0.2687461  0.26860494 0.26846401 0.26832331\n",
      " 0.26818283 0.26804258 0.26790256 0.26776276 0.26762319 0.26748384\n",
      " 0.26734472 0.26720582 0.26706714 0.26692869 0.26679046 0.26665245\n",
      " 0.26651466 0.2663771  0.26623975 0.26610263 0.26596572 0.26582904\n",
      " 0.26569257 0.26555632 0.26542029 0.26528448 0.26514888 0.2650135\n",
      " 0.26487834 0.26474339 0.26460866 0.26447414 0.26433983 0.26420574\n",
      " 0.26407187 0.2639382  0.26380475 0.26367152 0.26353849 0.26340567\n",
      " 0.26327307 0.26314067 0.26300849 0.26287651 0.26274475 0.26261319\n",
      " 0.26248184 0.2623507  0.26221977 0.26208904 0.26195852 0.26182821\n",
      " 0.2616981  0.2615682  0.2614385  0.26130901 0.26117972 0.26105063\n",
      " 0.26092175 0.26079307 0.26066459 0.26053632 0.26040824 0.26028037\n",
      " 0.2601527  0.26002523 0.25989795 0.25977088 0.25964401 0.25951733\n",
      " 0.25939086 0.25926458 0.2591385  0.25901262 0.25888693 0.25876144\n",
      " 0.25863615 0.25851105 0.25838614 0.25826144 0.25813692 0.2580126\n",
      " 0.25788847 0.25776454 0.2576408  0.25751725 0.25739389 0.25727073\n",
      " 0.25714776 0.25702497 0.25690238 0.25677998 0.25665777 0.25653575\n",
      " 0.25641391 0.25629227 0.25617081 0.25604954 0.25592846 0.25580756\n",
      " 0.25568686 0.25556634 0.255446   0.25532585 0.25520589 0.25508611\n",
      " 0.25496651 0.2548471  0.25472787 0.25460883 0.25448997 0.25437129\n",
      " 0.2542528  0.25413448 0.25401635 0.2538984  0.25378063 0.25366304\n",
      " 0.25354563 0.25342841 0.25331136 0.25319449 0.25307779 0.25296128\n",
      " 0.25284495 0.25272879 0.25261281 0.25249701 0.25238138 0.25226593\n",
      " 0.25215066 0.25203556 0.25192064 0.25180589 0.25169132 0.25157692\n",
      " 0.25146269 0.25134864 0.25123476 0.25112106 0.25100753 0.25089417\n",
      " 0.25078098 0.25066796 0.25055511 0.25044244 0.25032994 0.2502176\n",
      " 0.25010544 0.24999344 0.24988162 0.24976996 0.24965848 0.24954716\n",
      " 0.24943601 0.24932502 0.24921421 0.24910356 0.24899308 0.24888276\n",
      " 0.24877261 0.24866262 0.24855281 0.24844315 0.24833366 0.24822434\n",
      " 0.24811518 0.24800618 0.24789735 0.24778868 0.24768017 0.24757182\n",
      " 0.24746364 0.24735562 0.24724776 0.24714006 0.24703253 0.24692515\n",
      " 0.24681793 0.24671088 0.24660398 0.24649725 0.24639067 0.24628425\n",
      " 0.24617799 0.24607189 0.24596594 0.24586016 0.24575453 0.24564906\n",
      " 0.24554374 0.24543858 0.24533358 0.24522873 0.24512404 0.24501951\n",
      " 0.24491513 0.2448109  0.24470683 0.24460291 0.24449915 0.24439554\n",
      " 0.24429208 0.24418877 0.24408562 0.24398262 0.24387977 0.24377708\n",
      " 0.24367453 0.24357214 0.2434699  0.24336781 0.24326587 0.24316407\n",
      " 0.24306243 0.24296094 0.2428596  0.2427584  0.24265736 0.24255646\n",
      " 0.24245571 0.24235511 0.24225466 0.24215435 0.24205419 0.24195418\n",
      " 0.24185432 0.2417546  0.24165502 0.24155559 0.24145631 0.24135717\n",
      " 0.24125818 0.24115933 0.24106063 0.24096206 0.24086365 0.24076537\n",
      " 0.24066724 0.24056926 0.24047141 0.24037371 0.24027615 0.24017873\n",
      " 0.24008145 0.23998432 0.23988732 0.23979047 0.23969376 0.23959719\n",
      " 0.23950075 0.23940446 0.23930831 0.23921229 0.23911642 0.23902068\n",
      " 0.23892508 0.23882962 0.2387343  0.23863912 0.23854407 0.23844916\n",
      " 0.23835439 0.23825975 0.23816525 0.23807089 0.23797666 0.23788257\n",
      " 0.23778861 0.23769479 0.2376011  0.23750755 0.23741414 0.23732085\n",
      " 0.2372277  0.23713469 0.23704181 0.23694906 0.23685644 0.23676396\n",
      " 0.23667161 0.23657939 0.23648731 0.23639535 0.23630353 0.23621184\n",
      " 0.23612028 0.23602885 0.23593755 0.23584638 0.23575534 0.23566443\n",
      " 0.23557365 0.235483   0.23539248 0.23530209 0.23521182 0.23512169\n",
      " 0.23503168 0.2349418  0.23485205 0.23476243 0.23467293 0.23458356\n",
      " 0.23449432 0.23440521 0.23431622 0.23422735 0.23413862 0.23405\n",
      " 0.23396152 0.23387316 0.23378492 0.23369681 0.23360882 0.23352096\n",
      " 0.23343322 0.23334561 0.23325812 0.23317075 0.23308351 0.23299638\n",
      " 0.23290939 0.23282251 0.23273576 0.23264912 0.23256261 0.23247623\n",
      " 0.23238996 0.23230381 0.23221779 0.23213189 0.2320461  0.23196044\n",
      " 0.2318749  0.23178948 0.23170417 0.23161899 0.23153393 0.23144898\n",
      " 0.23136415 0.23127945 0.23119486 0.23111039 0.23102603 0.2309418\n",
      " 0.23085768 0.23077368 0.2306898  0.23060603 0.23052238 0.23043885\n",
      " 0.23035543 0.23027213 0.23018895 0.23010588 0.23002293 0.22994009\n",
      " 0.22985737 0.22977476 0.22969227 0.22960989 0.22952762 0.22944547\n",
      " 0.22936344 0.22928151 0.22919971 0.22911801 0.22903643 0.22895496\n",
      " 0.2288736  0.22879236 0.22871122 0.2286302  0.22854929 0.2284685\n",
      " 0.22838781 0.22830724 0.22822678 0.22814642 0.22806618 0.22798605\n",
      " 0.22790603 0.22782612 0.22774632 0.22766663 0.22758705 0.22750758\n",
      " 0.22742822 0.22734896 0.22726982 0.22719078 0.22711186 0.22703304\n",
      " 0.22695432 0.22687572 0.22679723 0.22671884 0.22664056 0.22656238\n",
      " 0.22648432 0.22640636 0.2263285  0.22625075 0.22617311 0.22609558\n",
      " 0.22601815 0.22594082 0.22586361 0.22578649 0.22570948 0.22563258\n",
      " 0.22555578 0.22547909 0.2254025  0.22532601]\n"
     ]
    }
   ],
   "source": [
    "ad = Linear()\n",
    "ad.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graff(sr.loss,sr.val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-65-b25382ab984e>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-b25382ab984e>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    print 'accuracy:', accuracy_score(y_true, y_pred)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    data_fname = 'train800.csv'\n",
    "    label_fname = 'trainLabels800.csv'\n",
    "    test_data_fname = 'test200.csv'\n",
    "    test_label_fname = 'testLabels200.csv'\n",
    "\n",
    "    adam = Adam(40, loss_type='hinge')\n",
    "    adam.fit(data_fname, label_fname)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with open(test_data_fname, 'r') as f_data, open(test_label_fname, 'r') as f_label:\n",
    "        for data, label in izip(f_data, f_label):\n",
    "            pred_label = adam.predict(np.array(data.rstrip().split(','), dtype=np.float64))\n",
    "            y_true.append(int(label))\n",
    "            y_pred.append( 1 if pred_label>0 else 0)\n",
    "    print 'accuracy:', accuracy_score(y_true, y_pred)\n",
    "    print 'recall:', recall_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import izip\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "def get_data(data_fname, label_fname):\n",
    "    result_data = []\n",
    "    result_labels = []\n",
    "    with open(data_fname, 'r') as f_data, open(label_fname, 'r') as f_label:\n",
    "        for data, label in izip(f_data, f_label):\n",
    "            result_data.append(data.rstrip().split(','))\n",
    "            result_labels.append(int(label.rstrip()))\n",
    "    return np.array(result_data, dtype=np.float64), result_labels\n",
    "\n",
    "if __name__=='__main__':\n",
    "     data_fname = 'train800.csv'\n",
    "    label_fname = 'trainLabels800.csv'\n",
    "    test_data_fname = 'test200.csv'\n",
    "    test_label_fname = 'testLabels200.csv'\n",
    "\n",
    "    data, labels = get_data(data_fname, label_fname)\n",
    "    test_data, test_labels = get_data(test_data_fname, test_label_fname)\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "    model = lr.fit(data, labels)\n",
    "    y_pred = model.predict(test_data)\n",
    "    print 'accuracy:', model.score(test_data, test_labels)\n",
    "    print 'recall:', recall_score(test_labels, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
