{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.inline\n"
   ]
  },
  {
   "source": [
    "## Sprint ディープラーニングフレームワーク2\n",
    "\n",
    "### 2.公式Example\n",
    "\n",
    "\n",
    "深層学習フレームワークには公式に様々なモデルのExampleコードが公開されています。\n",
    "\n",
    "#### 【問題1】公式チュートリアルモデルを分担して実行\n",
    "--------------\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "[models/tutorials at master · tensorflow/models](https://www.tensorflow.org/tutorials/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[テンソルと演算](https://www.tensorflow.org/tutorials/customization/basics#tensorflow%E3%81%AE%E3%82%A4%E3%83%B3%E3%83%9D%E3%83%BC%E3%83%88)\n",
    "\n",
    "これは、下記の手法を示す TensorFlow の入門チュートリアルです。\n",
    "\n",
    "    必要なパッケージのインポート\n",
    "    テンソルの作成と使用\n",
    "    GPUによる高速化の使用\n",
    "    tf.data.Datasetのデモ\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q tensorflow-gpu==2.0.0-rc1\n"
   ]
  },
  {
   "source": [
    "上記のコマンドを実行できなかったので下記のリンクで行う\n",
    "\n",
    "\n",
    "[tensorflow_macos ](https://github.com/apple/tensorflow_macos/issues/153)\n",
    "\n",
    "macbook Air inter big sur 　conda環境で動作確認済み\n",
    "\n",
    "### TensorFlowのインポート\n",
    "はじめに、tensorflow モジュールをインポートします。TensorFlow 2.0 では、eager execution が既定でオンとなっています。 これにより、TensorFlow のフロントエンドがよりインタラクティブになります。詳細は後述します。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-35bc9c9d47d4>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-35bc9c9d47d4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import tensorflow-macos  as tf\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow-macos  as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.4.0-rc0'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "source": [
    "### テンソル\n",
    "テンソルは多次元配列です。NumPy の ndarray オブジェクトと同様に、tf.Tensor にはデータ型と形状があります。これに加えて、tf.Tensor は（ GPU のような）アクセラレータのメモリに置くことができます。TensorFlow には、tf.Tensor を使用し生成するたくさんの演算(tf.add, tf.matmul, tf.linalg.inv など)のライブラリが存在します。これらの演算では、ネイティブな Python データ型が自動変換されます。例を示します。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\ntf.Tensor([4 6], shape=(2,), dtype=int32)\ntf.Tensor(25, shape=(), dtype=int32)\ntf.Tensor(6, shape=(), dtype=int32)\ntf.Tensor(13, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "\n",
    "# Operator overloading is also supported\n",
    "print(tf.square(2) + tf.square(3))\n"
   ]
  },
  {
   "source": [
    "それぞれのtf.Tensorには、形状とデータ型があります。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n(1, 2)\n<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.matmul([[1]], [[2, 3]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)\n"
   ]
  },
  {
   "source": [
    "NumPy 配列と tf.Tensor の間のもっとも明確な違いは\n",
    "\n",
    "    テンソルは（ GPU や TPU などの）アクセラレータメモリを使用できる\n",
    "    テンソルは変更不可\n",
    "\n",
    "### NumPy互換性\n",
    "\n",
    "TensorFlow のtf.Tensorと NumPy の ndarray 間の変換は簡単です。\n",
    "\n",
    "    TensorFlow の演算により NumPy の ndarray は自動的にテンソルに変換される\n",
    "    NumPy の演算によりテンソルは自動的に NuｍPy の ndarray に変換される\n",
    "\n",
    "テンソルは .numpy() メソッドを使って明示的に NumPy の ndarray に変換されます。NumPy のndarray と tf.Tensor はその下敷きとなるメモリ上の表現が、できるかぎり共通化されているので、通常この変換のコストは小さいです。しかし、NumPy 配列はホスト側のメモリに置かれる一方、tf.Tensor はGPU のメモリに置かれる可能性もあるため、下層の表現をいつも共通化できるとは限りません。また、変換にはGPU からホスト側メモリへのコピーも関わってきます。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorFlow演算によりnumpy配列は自動的にテンソルに変換される\ntf.Tensor(\n[[42. 42. 42.]\n [42. 42. 42.]\n [42. 42. 42.]], shape=(3, 3), dtype=float64)\nまたNumPy演算によりテンソルは自動的にnumpy配列に変換される\n[[43. 43. 43.]\n [43. 43. 43.]\n [43. 43. 43.]]\n.numpy()メソッドによりテンソルは明示的にnumpy配列に変換される\n[[42. 42. 42.]\n [42. 42. 42.]\n [42. 42. 42.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"TensorFlow演算によりnumpy配列は自動的にテンソルに変換される\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "\n",
    "\n",
    "print(\"またNumPy演算によりテンソルは自動的にnumpy配列に変換される\")\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "print(\".numpy()メソッドによりテンソルは明示的にnumpy配列に変換される\")\n",
    "print(tensor.numpy())\n"
   ]
  },
  {
   "source": [
    "### GPU による高速化\n",
    "TensorFlow の演算の多くは、GPU を計算に使用することで高速化されます。TensorFlow は演算に注釈をつけなくとも、自動的に GPU と CPU のどちらかを選択し、必要であればテンソルを GPU メモリと CPU メモリの間でコピーして実行します。演算で生成されたテンソルは通常演算を実行したデバイスのメモリに置かれます。例を見てみましょう。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "利用できるGPUはあるか: \n[]\nテンソルはGPU #0にあるか:  \nFalse\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"利用できるGPUはあるか: \"),\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "\n",
    "print(\"テンソルはGPU #0にあるか:  \"),\n",
    "print(x.device.endswith('GPU:0'))\n"
   ]
  },
  {
   "source": [
    "上記は多分nvidiaなどのグラフィックボード用のコードだと推測される\n",
    "今回はmac用のものをインストールできているので次に進む"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### デバイス名\n",
    "\n",
    "Tensor.device プロパティにより、そのテンソルの内容を保持しているデバイスの完全な名前文字列を得ることができます。この名前には、プログラムを実行中のホストのネットワークアドレスや、ホスト上のデバイスについての詳細がエンコードされています。この情報は、TensorFlow プログラムの分散実行に必要なものです。テンソルがホスト上の N 番目のGPUにある場合、文字列の最後は GPU:<N> となります。\n",
    "### 明示的デバイス配置\n",
    "TensorFlowでいう配置は、個々の演算を実行するためにどのようにデバイスにアサイン（配置）されるかを指します。前述のとおり、明示的な示唆がなければ、TensorFlow は演算を実行するデバイスを自動的に決め、必要であればテンソルをそのデバイスにコピーします。しかし、tf.device コンテキストマネジャーを使うことで、TensorFlow の演算を特定のデバイスに配置することができます。例を見てみましょう。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "On CPU:\n",
      "10 loops: 492.30ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def time_matmul(x):\n",
    "  start = time.time()\n",
    "  for loop in range(10):\n",
    "    tf.matmul(x, x)\n",
    "\n",
    "  result = time.time()-start\n",
    "\n",
    "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
    "\n",
    "# CPUでの実行を強制\n",
    "print(\"On CPU:\")\n",
    "with tf.device(\"CPU:0\"):\n",
    "  x = tf.random.uniform([1000, 1000])\n",
    "  assert x.device.endswith(\"CPU:0\")\n",
    "  time_matmul(x)\n",
    "\n",
    "# GPU #0があればその上での実行を強制\n",
    "if tf.config.experimental.list_physical_devices(\"GPU\"):\n",
    "  print(\"On GPU:\")\n",
    "  with tf.device(\"GPU:0\"): # 2番めのGPUなら GPU:1, 3番目なら GPU:2 など\n",
    "    x = tf.random.uniform([1000, 1000])\n",
    "    assert x.device.endswith(\"GPU:0\")\n",
    "    time_matmul(x)\n"
   ]
  },
  {
   "source": [
    "### データセット\n",
    "\n",
    "このセクションでは tf.data.Dataset API を使って、モデルにデータを供給するためのパイプラインを構築します。tf.data.Dataset APIは、単純で再利用可能な部品をもとに、モデルの訓練あるいは評価ループにデータを供給する高性能で複雑な入力パイプラインを構築するために使われます。\n",
    "### ソースDatasetの作成\n",
    "Dataset.from_tensors やDataset.from_tensor_slices といったファクトリー関数または TextLineDataset あるいはTFRecordDataset のようなファイルを読み込むオブジェクトを使って、 元となるデータセットを作成しましょう。詳しくは、TensorFlow Dataset guide を参照してください。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# CSVファイルを作成\n",
    "import tempfile\n",
    "_, filename = tempfile.mkstemp()\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "  f.write(\"\"\"Line 1\n",
    "Line 2\n",
    "Line 3\n",
    "  \"\"\")\n",
    "\n",
    "ds_file = tf.data.TextLineDataset(filename)\n"
   ]
  },
  {
   "source": [
    "### 変換の適用\n",
    "map, batch, shuffle などの変換関数を使って、データセットレコードに変換を適用します。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
    "\n",
    "ds_file = ds_file.batch(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ds_tensors の要素:\n",
      "tf.Tensor([1 9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 4 16], shape=(2,), dtype=int32)\n",
      "tf.Tensor([36 25], shape=(2,), dtype=int32)\n",
      "\n",
      "ds_file の要素:\n",
      "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Line 3' b'  '], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print('ds_tensors の要素:')\n",
    "for x in ds_tensors:\n",
    "  print(x)\n",
    "\n",
    "print('\\nds_file の要素:')\n",
    "for x in ds_file:\n",
    "  print(x)\n"
   ]
  },
  {
   "source": [
    "#### 【問題2】（アドバンス課題）様々な手法を実行\n",
    "----------------\n",
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。\n",
    "\n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。\n",
    "\n",
    "[models/research at master · tensorflow/models](https://github.com/tensorflow/models/tree/master/research)\n",
    "\n",
    "[google-research/google-research: Google AI Research](https://github.com/google-research/google-research)\n",
    "\n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### 3.異なるフレームワークへの書き換え\n",
    "\n",
    "\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。\n",
    "\n",
    "Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "Iris（3種類全ての目的変数を使用して多値分類）\n",
    "House Prices\n",
    "MNIST\n",
    "\n",
    "#### Kerasへの書き換え\n",
    "--------------\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。\n",
    "\n",
    "#### 【問題3】Iris（2値分類）をKerasで学習\n",
    "--------------\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data[:100,:]\n",
    "y = iris.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 274
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, input_dim=4))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.add(tf.keras.layers.Activation('sigmoid')) \n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_49\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_81 (Dense)             (None, 64)                320       \n_________________________________________________________________\nactivation_66 (Activation)   (None, 64)                0         \n_________________________________________________________________\ndense_82 (Dense)             (None, 32)                2080      \n_________________________________________________________________\nactivation_67 (Activation)   (None, 32)                0         \n_________________________________________________________________\ndense_83 (Dense)             (None, 1)                 33        \n_________________________________________________________________\nactivation_68 (Activation)   (None, 1)                 0         \n=================================================================\nTotal params: 2,433\nTrainable params: 2,433\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "80/80 [==============================] - 1s 4ms/step - loss: 0.4694 - accuracy: 0.7961 - val_loss: 0.1174 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.2352e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.4412e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 0s 4ms/step - loss: 8.3289e-04 - accuracy: 1.0000 - val_loss: 5.8647e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 9.8524e-04 - accuracy: 1.0000 - val_loss: 4.6243e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 6.7839e-04 - accuracy: 1.0000 - val_loss: 3.5709e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 4.2197e-04 - accuracy: 1.0000 - val_loss: 3.1348e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.9910e-04 - accuracy: 1.0000 - val_loss: 2.7475e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.6405e-04 - accuracy: 1.0000 - val_loss: 2.3061e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 0s 3ms/step - loss: 2.5286e-04 - accuracy: 1.0000 - val_loss: 2.0513e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 3.5714e-04 - accuracy: 1.0000 - val_loss: 1.6038e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 4.3734e-04 - accuracy: 1.0000 - val_loss: 1.4717e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9cd426a1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[9.9998498e-01],\n",
       "       [9.9999821e-01],\n",
       "       [3.7465645e-05],\n",
       "       [5.9486447e-05],\n",
       "       [1.7929077e-04],\n",
       "       [3.6299229e-04],\n",
       "       [9.9998677e-01],\n",
       "       [5.5846572e-04],\n",
       "       [9.9999869e-01],\n",
       "       [9.9997675e-01],\n",
       "       [6.3446164e-04],\n",
       "       [4.7916174e-04],\n",
       "       [9.9999189e-01],\n",
       "       [2.4646521e-04],\n",
       "       [8.1200618e-05],\n",
       "       [8.3259285e-05],\n",
       "       [8.7203240e-05],\n",
       "       [9.9999136e-01],\n",
       "       [5.8486723e-05],\n",
       "       [9.9999648e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 278
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4717e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0001471704599680379, 1.0]"
      ]
     },
     "metadata": {},
     "execution_count": 279
    }
   ],
   "source": [
    "model.metrics_names\n",
    "model.evaluate(X_test,y_test, batch_size=10)"
   ]
  },
  {
   "source": [
    "#### 【問題4】Iris（多値分類）をKerasで学習\n",
    "----------------------\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=19)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(12, input_dim=4))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dense(3, input_dim=12))\n",
    "model.add(tf.keras.layers.Activation('softmax')) \n",
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 2s 7ms/step - loss: 1.4113 - accuracy: 0.3732 - val_loss: 1.0598 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 1.1030 - accuracy: 0.4197 - val_loss: 0.8874 - val_accuracy: 0.5667\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.8960 - accuracy: 0.5102 - val_loss: 0.8023 - val_accuracy: 0.4667\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.7620 - accuracy: 0.5272 - val_loss: 0.7207 - val_accuracy: 0.4333\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6886 - accuracy: 0.6637 - val_loss: 0.6509 - val_accuracy: 0.7667\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.8502 - val_loss: 0.5835 - val_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.8587 - val_loss: 0.5384 - val_accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.9261 - val_loss: 0.5044 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8937 - val_loss: 0.4464 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.9343 - val_loss: 0.4243 - val_accuracy: 0.9667\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.9133 - val_loss: 0.4077 - val_accuracy: 0.9333\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.9268 - val_loss: 0.3994 - val_accuracy: 0.8333\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.9076 - val_loss: 0.3646 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.9648 - val_loss: 0.3608 - val_accuracy: 0.9333\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8992 - val_loss: 0.3737 - val_accuracy: 0.8333\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.9089 - val_loss: 0.3341 - val_accuracy: 0.9667\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.9329 - val_loss: 0.3059 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.9418 - val_loss: 0.2944 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.9589 - val_loss: 0.2946 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.9133 - val_loss: 0.2899 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[9.34664130e-01, 6.37958050e-02, 1.54001685e-03],\n",
       "       [3.66249995e-04, 2.77208716e-01, 7.22425044e-01],\n",
       "       [7.95551017e-03, 5.21336496e-01, 4.70707923e-01],\n",
       "       [2.18699947e-02, 6.17851138e-01, 3.60278964e-01],\n",
       "       [9.46399927e-01, 5.27066700e-02, 8.93365243e-04],\n",
       "       [9.42205369e-01, 5.66952378e-02, 1.09934469e-03],\n",
       "       [9.27082956e-01, 7.08366260e-02, 2.08051968e-03],\n",
       "       [9.42058265e-01, 5.68346679e-02, 1.10706466e-03],\n",
       "       [1.27738984e-02, 5.67667365e-01, 4.19558704e-01],\n",
       "       [4.29460088e-05, 1.86832651e-01, 8.13124418e-01],\n",
       "       [1.52144935e-02, 5.34833848e-01, 4.49951649e-01],\n",
       "       [9.19470310e-01, 7.85493925e-02, 1.98032125e-03],\n",
       "       [7.25826249e-03, 5.53274632e-01, 4.39467072e-01],\n",
       "       [9.37170327e-01, 6.14704341e-02, 1.35920849e-03],\n",
       "       [5.39399334e-04, 3.00176352e-01, 6.99284315e-01],\n",
       "       [9.26956713e-01, 7.09528700e-02, 2.09037890e-03],\n",
       "       [8.58111889e-05, 1.84155703e-01, 8.15758526e-01],\n",
       "       [9.56743121e-01, 4.27623242e-02, 4.94510285e-04],\n",
       "       [6.00216687e-02, 6.87528193e-01, 2.52450109e-01],\n",
       "       [9.53268588e-01, 4.61424254e-02, 5.89017349e-04],\n",
       "       [3.19770537e-02, 6.56685710e-01, 3.11337203e-01],\n",
       "       [8.01660214e-03, 5.82191944e-01, 4.09791440e-01],\n",
       "       [1.99822336e-02, 6.93022966e-01, 2.86994815e-01],\n",
       "       [1.70212761e-02, 6.04880691e-01, 3.78098100e-01],\n",
       "       [4.98914043e-04, 2.24285960e-01, 7.75215149e-01],\n",
       "       [7.69414101e-03, 6.26845181e-01, 3.65460694e-01],\n",
       "       [4.06786450e-04, 2.29827747e-01, 7.69765437e-01],\n",
       "       [4.07478889e-04, 2.79212624e-01, 7.20379889e-01],\n",
       "       [3.57534401e-02, 6.82877421e-01, 2.81369179e-01],\n",
       "       [1.33413720e-04, 1.43055275e-01, 8.56811345e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2899 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.28991222381591797, 1.0]"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "model.metrics_names\n",
    "model.evaluate(X_test,y_test, batch_size=10)"
   ]
  },
  {
   "source": [
    "#### 【問題5】House PricesをKerasで学習\n",
    "------------------\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../term1/Sprint/train.csv\")\n",
    "X = df[[\"YearBuilt\",\"GrLivArea\"]]\n",
    "y = df[[\"SalePrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X = mms.fit_transform(X)\n",
    "y = mms.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, input_dim=X.shape[1]))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.add(tf.keras.layers.Activation('relu')) \n",
    "model.compile(optimizer='RMSProp',loss='mean_squared_error',metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 0.0181 - mae: 0.0894 - val_loss: 0.0032 - val_mae: 0.0377\n",
      "Epoch 2/5\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 0.0046 - mae: 0.0471 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 3/5\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 0.0045 - mae: 0.0455 - val_loss: 0.0037 - val_mae: 0.0474\n",
      "Epoch 4/5\n",
      "934/934 [==============================] - 2s 2ms/step - loss: 0.0047 - mae: 0.0467 - val_loss: 0.0030 - val_mae: 0.0378\n",
      "Epoch 5/5\n",
      "934/934 [==============================] - 2s 3ms/step - loss: 0.0038 - mae: 0.0431 - val_loss: 0.0028 - val_mae: 0.0375\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "30/30 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.30630293],\n",
       "       [0.15522876],\n",
       "       [0.12248225],\n",
       "       [0.2654441 ],\n",
       "       [0.13500974],\n",
       "       [0.06374262],\n",
       "       [0.23222509],\n",
       "       [0.12878211],\n",
       "       [0.6185987 ],\n",
       "       [0.18402173],\n",
       "       [0.21718492],\n",
       "       [0.21399179],\n",
       "       [0.295238  ],\n",
       "       [0.10838627],\n",
       "       [0.10703231],\n",
       "       [0.14197531],\n",
       "       [0.27489737],\n",
       "       [0.15584551],\n",
       "       [0.14350724],\n",
       "       [0.16271447],\n",
       "       [0.14468254],\n",
       "       [0.15492292],\n",
       "       [0.0939771 ],\n",
       "       [0.21503676],\n",
       "       [0.23892067],\n",
       "       [0.11150587],\n",
       "       [0.23692353],\n",
       "       [0.0850068 ],\n",
       "       [0.2659527 ],\n",
       "       [0.12083102],\n",
       "       [0.19897167],\n",
       "       [0.25497302],\n",
       "       [0.12427593],\n",
       "       [0.32956475],\n",
       "       [0.31921667],\n",
       "       [0.21379876],\n",
       "       [0.2430643 ],\n",
       "       [0.11294258],\n",
       "       [0.31853807],\n",
       "       [0.38587442],\n",
       "       [0.24512976],\n",
       "       [0.14500585],\n",
       "       [0.21064016],\n",
       "       [0.28110838],\n",
       "       [0.41626233],\n",
       "       [0.20154244],\n",
       "       [0.08583949],\n",
       "       [0.11960673],\n",
       "       [0.2176475 ],\n",
       "       [0.08815185],\n",
       "       [0.40741187],\n",
       "       [0.12495678],\n",
       "       [0.17159022],\n",
       "       [0.06751186],\n",
       "       [0.22975561],\n",
       "       [0.11049654],\n",
       "       [0.10932489],\n",
       "       [0.27764517],\n",
       "       [0.12770459],\n",
       "       [0.07460841],\n",
       "       [0.12029561],\n",
       "       [0.11150934],\n",
       "       [0.1333437 ],\n",
       "       [0.1324127 ],\n",
       "       [0.24272504],\n",
       "       [0.16012383],\n",
       "       [0.09824405],\n",
       "       [0.26822978],\n",
       "       [0.08902571],\n",
       "       [0.26469764],\n",
       "       [0.22392724],\n",
       "       [0.09764203],\n",
       "       [0.09588076],\n",
       "       [0.2267528 ],\n",
       "       [0.10177298],\n",
       "       [0.25688675],\n",
       "       [0.11293352],\n",
       "       [0.07326782],\n",
       "       [0.37774512],\n",
       "       [0.14912459],\n",
       "       [0.12961365],\n",
       "       [0.11910008],\n",
       "       [0.09978213],\n",
       "       [0.15584551],\n",
       "       [0.35923746],\n",
       "       [0.21097341],\n",
       "       [0.08982682],\n",
       "       [0.21765386],\n",
       "       [0.20465289],\n",
       "       [0.11711757],\n",
       "       [0.24946634],\n",
       "       [0.19894984],\n",
       "       [0.2185742 ],\n",
       "       [0.28155404],\n",
       "       [0.20581785],\n",
       "       [0.13854192],\n",
       "       [0.23039491],\n",
       "       [0.14707813],\n",
       "       [0.10827338],\n",
       "       [0.14401613],\n",
       "       [0.26799628],\n",
       "       [0.29233837],\n",
       "       [0.14485249],\n",
       "       [0.18265174],\n",
       "       [0.04769856],\n",
       "       [0.34832835],\n",
       "       [0.1992107 ],\n",
       "       [0.08079389],\n",
       "       [0.23196588],\n",
       "       [0.10450378],\n",
       "       [0.03042961],\n",
       "       [0.11500445],\n",
       "       [0.25123888],\n",
       "       [0.10218854],\n",
       "       [0.21898966],\n",
       "       [0.19581634],\n",
       "       [0.36388963],\n",
       "       [0.11874745],\n",
       "       [0.26899064],\n",
       "       [0.3027684 ],\n",
       "       [0.18136136],\n",
       "       [0.22348782],\n",
       "       [0.11047963],\n",
       "       [0.24406034],\n",
       "       [0.23750639],\n",
       "       [0.23738487],\n",
       "       [0.3274449 ],\n",
       "       [0.21101767],\n",
       "       [0.20376216],\n",
       "       [0.19280334],\n",
       "       [0.20299949],\n",
       "       [0.20364125],\n",
       "       [0.30183572],\n",
       "       [0.19043978],\n",
       "       [0.10827338],\n",
       "       [0.24917832],\n",
       "       [0.1443663 ],\n",
       "       [0.20802696],\n",
       "       [0.09318654],\n",
       "       [0.22862536],\n",
       "       [0.1168385 ],\n",
       "       [0.18185982],\n",
       "       [0.26365158],\n",
       "       [0.13720638],\n",
       "       [0.15084255],\n",
       "       [0.21595697],\n",
       "       [0.23251334],\n",
       "       [0.11527856],\n",
       "       [0.27058852],\n",
       "       [0.22256032],\n",
       "       [0.16286488],\n",
       "       [0.26810026],\n",
       "       [0.28065452],\n",
       "       [0.17434976],\n",
       "       [0.15174256],\n",
       "       [0.38455027],\n",
       "       [0.10171287],\n",
       "       [0.13684762],\n",
       "       [0.19059595],\n",
       "       [0.21217853],\n",
       "       [0.10960514],\n",
       "       [0.13019355],\n",
       "       [0.24679731],\n",
       "       [0.11897006],\n",
       "       [0.246509  ],\n",
       "       [0.12728822],\n",
       "       [0.1659458 ],\n",
       "       [0.34537005],\n",
       "       [0.21497877],\n",
       "       [0.25377312],\n",
       "       [0.15541221],\n",
       "       [0.20382263],\n",
       "       [0.21015646],\n",
       "       [0.163166  ],\n",
       "       [0.10280976],\n",
       "       [0.13690396],\n",
       "       [0.12537552],\n",
       "       [0.35257912],\n",
       "       [0.10910005],\n",
       "       [0.1502079 ],\n",
       "       [0.29195738],\n",
       "       [0.23556656],\n",
       "       [0.08397448],\n",
       "       [0.26681754],\n",
       "       [0.07464825],\n",
       "       [0.2101421 ],\n",
       "       [0.12197851],\n",
       "       [0.20122272],\n",
       "       [0.22323126],\n",
       "       [0.15492292],\n",
       "       [0.15584551],\n",
       "       [0.14888033],\n",
       "       [0.23774582],\n",
       "       [0.15016538],\n",
       "       [0.08733023],\n",
       "       [0.14247607],\n",
       "       [0.0850068 ],\n",
       "       [0.12352884],\n",
       "       [0.19661678],\n",
       "       [0.16616623],\n",
       "       [0.1457718 ],\n",
       "       [0.1756201 ],\n",
       "       [0.06544434],\n",
       "       [0.13853815],\n",
       "       [0.17455927],\n",
       "       [0.34601834],\n",
       "       [0.1434274 ],\n",
       "       [0.32271782],\n",
       "       [0.2693197 ],\n",
       "       [0.05005641],\n",
       "       [0.18547282],\n",
       "       [0.24830058],\n",
       "       [0.10444439],\n",
       "       [0.0507715 ],\n",
       "       [0.24532354],\n",
       "       [0.3003331 ],\n",
       "       [0.18084824],\n",
       "       [0.390983  ],\n",
       "       [0.25832808],\n",
       "       [0.08767477],\n",
       "       [0.19276111],\n",
       "       [0.16486333],\n",
       "       [0.1353505 ],\n",
       "       [0.11093695],\n",
       "       [0.23513685],\n",
       "       [0.31122655],\n",
       "       [0.2896768 ],\n",
       "       [0.22774646],\n",
       "       [0.1379024 ],\n",
       "       [0.17439245],\n",
       "       [0.10341443],\n",
       "       [0.10119779],\n",
       "       [0.10960514],\n",
       "       [0.17046614],\n",
       "       [0.26735136],\n",
       "       [0.13483742],\n",
       "       [0.2268548 ],\n",
       "       [0.08568097],\n",
       "       [0.12198821],\n",
       "       [0.16350609],\n",
       "       [0.12838627],\n",
       "       [0.25003555],\n",
       "       [0.26931286],\n",
       "       [0.2691757 ],\n",
       "       [0.16140717],\n",
       "       [0.15574837],\n",
       "       [0.18539964],\n",
       "       [0.24452016],\n",
       "       [0.12425143],\n",
       "       [0.21645965],\n",
       "       [0.15803993],\n",
       "       [0.29972196],\n",
       "       [0.0577255 ],\n",
       "       [0.45878002],\n",
       "       [0.21698733],\n",
       "       [0.28110838],\n",
       "       [0.08004576],\n",
       "       [0.24735929],\n",
       "       [0.5024969 ],\n",
       "       [0.75542855],\n",
       "       [0.25925246],\n",
       "       [0.14670008],\n",
       "       [0.19657992],\n",
       "       [0.08445598],\n",
       "       [0.32340696],\n",
       "       [0.27889585],\n",
       "       [0.36171234],\n",
       "       [0.026993  ],\n",
       "       [0.21297431],\n",
       "       [0.26694715],\n",
       "       [0.12802298],\n",
       "       [0.2028445 ],\n",
       "       [0.14614442],\n",
       "       [0.20532668],\n",
       "       [0.19831574],\n",
       "       [0.31861284],\n",
       "       [0.2436791 ],\n",
       "       [0.17481501],\n",
       "       [0.29789677],\n",
       "       [0.10814866],\n",
       "       [0.11427964],\n",
       "       [0.3027712 ],\n",
       "       [0.14686543],\n",
       "       [0.156893  ],\n",
       "       [0.21017121],\n",
       "       [0.24295308],\n",
       "       [0.15038092],\n",
       "       [0.24690826],\n",
       "       [0.37342274],\n",
       "       [0.23484123],\n",
       "       [0.05809254],\n",
       "       [0.08319824]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 322
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0058 - mae: 0.0498\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0058202496729791164, 0.049791280180215836]"
      ]
     },
     "metadata": {},
     "execution_count": 335
    }
   ],
   "source": [
    "model.metrics_names\n",
    "model.evaluate(X_test,y_test, batch_size=10)"
   ]
  },
  {
   "source": [
    "#### 【問題6】MNISTをKerasで学習\n",
    "------------------\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.09310647, 0.06202954, 0.08150596, 0.12916912, 0.13066141,\n",
       "        0.0819173 , 0.03002794, 0.09720318, 0.16176642, 0.13261269]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.09924501, 0.09620821, 0.09810037, 0.10288937, 0.10304302,\n",
       "        0.09814073, 0.09317814, 0.09965242, 0.10629854, 0.10324428]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 169
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.321353"
      ]
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4277 - accuracy: 0.8790\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1157 - accuracy: 0.9661\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0780 - accuracy: 0.9764\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0557 - accuracy: 0.9834\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0429 - accuracy: 0.9864\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9d1ccedf10>"
      ]
     },
     "metadata": {},
     "execution_count": 173
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 - 1s - loss: 0.0789 - accuracy: 0.9740\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.07888893783092499, 0.9739999771118164]"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "source": [
    "#### 【問題7】（アドバンス課題）PyTorchへの書き換え\n",
    "-----------------\n",
    "4種類の問題をPyTorchに書き換えてください。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:100,:]\n",
    "y = iris.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "X_val = torch.from_numpy(X_val).float()\n",
    "y_val = torch.from_numpy(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([80, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4])\ntensor(1)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# indexを指定すればデータを取り出す\n",
    "index = 0\n",
    "print(train_dataset.__getitem__(index)[0].size())\n",
    "print(train_dataset.__getitem__(index)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([32, 4])\ntorch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# イテレータに変換\n",
    "batch_iterator = iter(train_dataloader)\n",
    "# 1番目の要素を取り出す\n",
    "inputs, labels = next(batch_iterator)\n",
    "print(inputs.size())\n",
    "print(labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n  (fc1): Linear(in_features=4, out_features=50, bias=True)\n  (fc2): Linear(in_features=50, out_features=2, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "-------------\n",
      "train Loss: 0.7158 Acc: 0.5250\n",
      "val Loss: 0.7290 Acc: 0.4000\n",
      "Epoch 2/50\n",
      "-------------\n",
      "train Loss: 0.6999 Acc: 0.5250\n",
      "val Loss: 0.7227 Acc: 0.4000\n",
      "Epoch 3/50\n",
      "-------------\n",
      "train Loss: 0.6904 Acc: 0.5250\n",
      "val Loss: 0.7077 Acc: 0.4000\n",
      "Epoch 4/50\n",
      "-------------\n",
      "train Loss: 0.6813 Acc: 0.5250\n",
      "val Loss: 0.7041 Acc: 0.4000\n",
      "Epoch 5/50\n",
      "-------------\n",
      "train Loss: 0.6716 Acc: 0.5250\n",
      "val Loss: 0.7032 Acc: 0.4000\n",
      "Epoch 6/50\n",
      "-------------\n",
      "train Loss: 0.6621 Acc: 0.5250\n",
      "val Loss: 0.6860 Acc: 0.4000\n",
      "Epoch 7/50\n",
      "-------------\n",
      "train Loss: 0.6529 Acc: 0.5250\n",
      "val Loss: 0.6729 Acc: 0.4000\n",
      "Epoch 8/50\n",
      "-------------\n",
      "train Loss: 0.6433 Acc: 0.5250\n",
      "val Loss: 0.6573 Acc: 0.4000\n",
      "Epoch 9/50\n",
      "-------------\n",
      "train Loss: 0.6350 Acc: 0.5375\n",
      "val Loss: 0.6523 Acc: 0.4000\n",
      "Epoch 10/50\n",
      "-------------\n",
      "train Loss: 0.6270 Acc: 0.5375\n",
      "val Loss: 0.6409 Acc: 0.4000\n",
      "Epoch 11/50\n",
      "-------------\n",
      "train Loss: 0.6258 Acc: 0.5375\n",
      "val Loss: 0.6201 Acc: 1.0000\n",
      "Epoch 12/50\n",
      "-------------\n",
      "train Loss: 0.6100 Acc: 0.9875\n",
      "val Loss: 0.6151 Acc: 0.9000\n",
      "Epoch 13/50\n",
      "-------------\n",
      "train Loss: 0.6027 Acc: 0.8875\n",
      "val Loss: 0.6023 Acc: 1.0000\n",
      "Epoch 14/50\n",
      "-------------\n",
      "train Loss: 0.5951 Acc: 0.9875\n",
      "val Loss: 0.6034 Acc: 0.9000\n",
      "Epoch 15/50\n",
      "-------------\n",
      "train Loss: 0.5925 Acc: 0.7500\n",
      "val Loss: 0.5835 Acc: 1.0000\n",
      "Epoch 16/50\n",
      "-------------\n",
      "train Loss: 0.5832 Acc: 1.0000\n",
      "val Loss: 0.5792 Acc: 1.0000\n",
      "Epoch 17/50\n",
      "-------------\n",
      "train Loss: 0.5725 Acc: 0.9875\n",
      "val Loss: 0.5688 Acc: 1.0000\n",
      "Epoch 18/50\n",
      "-------------\n",
      "train Loss: 0.5662 Acc: 1.0000\n",
      "val Loss: 0.5707 Acc: 1.0000\n",
      "Epoch 19/50\n",
      "-------------\n",
      "train Loss: 0.5590 Acc: 0.9875\n",
      "val Loss: 0.5573 Acc: 1.0000\n",
      "Epoch 20/50\n",
      "-------------\n",
      "train Loss: 0.5521 Acc: 1.0000\n",
      "val Loss: 0.5542 Acc: 1.0000\n",
      "Epoch 21/50\n",
      "-------------\n",
      "train Loss: 0.5467 Acc: 1.0000\n",
      "val Loss: 0.5513 Acc: 1.0000\n",
      "Epoch 22/50\n",
      "-------------\n",
      "train Loss: 0.5416 Acc: 0.9875\n",
      "val Loss: 0.5413 Acc: 1.0000\n",
      "Epoch 23/50\n",
      "-------------\n",
      "train Loss: 0.5337 Acc: 1.0000\n",
      "val Loss: 0.5300 Acc: 1.0000\n",
      "Epoch 24/50\n",
      "-------------\n",
      "train Loss: 0.5312 Acc: 1.0000\n",
      "val Loss: 0.5218 Acc: 1.0000\n",
      "Epoch 25/50\n",
      "-------------\n",
      "train Loss: 0.5224 Acc: 1.0000\n",
      "val Loss: 0.5233 Acc: 1.0000\n",
      "Epoch 26/50\n",
      "-------------\n",
      "train Loss: 0.5179 Acc: 1.0000\n",
      "val Loss: 0.5159 Acc: 1.0000\n",
      "Epoch 27/50\n",
      "-------------\n",
      "train Loss: 0.5119 Acc: 1.0000\n",
      "val Loss: 0.5110 Acc: 1.0000\n",
      "Epoch 28/50\n",
      "-------------\n",
      "train Loss: 0.5065 Acc: 1.0000\n",
      "val Loss: 0.4992 Acc: 1.0000\n",
      "Epoch 29/50\n",
      "-------------\n",
      "train Loss: 0.5012 Acc: 1.0000\n",
      "val Loss: 0.4944 Acc: 1.0000\n",
      "Epoch 30/50\n",
      "-------------\n",
      "train Loss: 0.4965 Acc: 1.0000\n",
      "val Loss: 0.4889 Acc: 1.0000\n",
      "Epoch 31/50\n",
      "-------------\n",
      "train Loss: 0.4921 Acc: 1.0000\n",
      "val Loss: 0.4885 Acc: 1.0000\n",
      "Epoch 32/50\n",
      "-------------\n",
      "train Loss: 0.4884 Acc: 1.0000\n",
      "val Loss: 0.4797 Acc: 1.0000\n",
      "Epoch 33/50\n",
      "-------------\n",
      "train Loss: 0.4834 Acc: 1.0000\n",
      "val Loss: 0.4753 Acc: 1.0000\n",
      "Epoch 34/50\n",
      "-------------\n",
      "train Loss: 0.4796 Acc: 1.0000\n",
      "val Loss: 0.4764 Acc: 1.0000\n",
      "Epoch 35/50\n",
      "-------------\n",
      "train Loss: 0.4763 Acc: 1.0000\n",
      "val Loss: 0.4749 Acc: 1.0000\n",
      "Epoch 36/50\n",
      "-------------\n",
      "train Loss: 0.4724 Acc: 1.0000\n",
      "val Loss: 0.4617 Acc: 1.0000\n",
      "Epoch 37/50\n",
      "-------------\n",
      "train Loss: 0.4678 Acc: 1.0000\n",
      "val Loss: 0.4604 Acc: 1.0000\n",
      "Epoch 38/50\n",
      "-------------\n",
      "train Loss: 0.4667 Acc: 1.0000\n",
      "val Loss: 0.4518 Acc: 1.0000\n",
      "Epoch 39/50\n",
      "-------------\n",
      "train Loss: 0.4615 Acc: 1.0000\n",
      "val Loss: 0.4540 Acc: 1.0000\n",
      "Epoch 40/50\n",
      "-------------\n",
      "train Loss: 0.4575 Acc: 1.0000\n",
      "val Loss: 0.4468 Acc: 1.0000\n",
      "Epoch 41/50\n",
      "-------------\n",
      "train Loss: 0.4564 Acc: 1.0000\n",
      "val Loss: 0.4458 Acc: 1.0000\n",
      "Epoch 42/50\n",
      "-------------\n",
      "train Loss: 0.4508 Acc: 1.0000\n",
      "val Loss: 0.4420 Acc: 1.0000\n",
      "Epoch 43/50\n",
      "-------------\n",
      "train Loss: 0.4480 Acc: 1.0000\n",
      "val Loss: 0.4401 Acc: 1.0000\n",
      "Epoch 44/50\n",
      "-------------\n",
      "train Loss: 0.4452 Acc: 1.0000\n",
      "val Loss: 0.4365 Acc: 1.0000\n",
      "Epoch 45/50\n",
      "-------------\n",
      "train Loss: 0.4422 Acc: 1.0000\n",
      "val Loss: 0.4361 Acc: 1.0000\n",
      "Epoch 46/50\n",
      "-------------\n",
      "train Loss: 0.4393 Acc: 1.0000\n",
      "val Loss: 0.4309 Acc: 1.0000\n",
      "Epoch 47/50\n",
      "-------------\n",
      "train Loss: 0.4366 Acc: 1.0000\n",
      "val Loss: 0.4276 Acc: 1.0000\n",
      "Epoch 48/50\n",
      "-------------\n",
      "train Loss: 0.4344 Acc: 1.0000\n",
      "val Loss: 0.4227 Acc: 1.0000\n",
      "Epoch 49/50\n",
      "-------------\n",
      "train Loss: 0.4326 Acc: 1.0000\n",
      "val Loss: 0.4280 Acc: 1.0000\n",
      "Epoch 50/50\n",
      "-------------\n",
      "train Loss: 0.4302 Acc: 1.0000\n",
      "val Loss: 0.4214 Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# エポック数\n",
    "num_epochs = 50\n",
    "\n",
    "# 学習時と検証時で分けるためディクショナリを用意\n",
    "dataloaders_dict = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "    print('-------------')\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        \n",
    "        if phase == 'train':\n",
    "            # モデルを訓練モードに設定\n",
    "            net.train()\n",
    "        else:\n",
    "            # モデルを推論モードに設定\n",
    "            net.eval()\n",
    "        \n",
    "        # 損失和\n",
    "        epoch_loss = 0.0\n",
    "        # 正解数\n",
    "        epoch_corrects = 0\n",
    "        \n",
    "        # DataLoaderからデータをバッチごとに取り出す\n",
    "        for inputs, labels in dataloaders_dict[phase]:\n",
    "            \n",
    "            # optimizerの初期化\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 学習時のみ勾配を計算させる設定にする\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                # 損失を計算\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # ラベルを予測\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                # 訓練時はバックプロパゲーション\n",
    "                if phase == 'train':\n",
    "                    # 逆伝搬の計算\n",
    "                    loss.backward()\n",
    "                    # パラメータの更新\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # イテレーション結果の計算\n",
    "                # lossの合計を更新\n",
    "                # PyTorchの仕様上各バッチ内での平均のlossが計算される。\n",
    "                # データ数を掛けることで平均から合計に変換をしている。\n",
    "                # 損失和は「全データの損失/データ数」で計算されるため、\n",
    "                # 平均のままだと損失和を求めることができないため。\n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                # 正解数の合計を更新\n",
    "                epoch_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # epochごとのlossと正解率を表示\n",
    "        epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n"
   ]
  },
  {
   "source": [
    "#### 【問題8】（アドバンス課題）フレームワークの比較\n",
    "------------------\n",
    "それぞれのフレームワークにはどのような違いがあるかをまとめてください。\n",
    "\n",
    "《視点例》\n",
    "\n",
    "計算速度\n",
    "コードの行数・可読性\n",
    "用意されている機能\n",
    "\n",
    "#### ２日目の発表について\n",
    "---------------------------\n",
    "今回のsprintでは１日目の夕方の発表を通常通り１名の方に行っていただき、２日目にはtensorflowのチュートリアルについての発表を全員に行っていただきます。 \n",
    "目安としての発表時間は5分-10分程度です。\n",
    "\n",
    "発表形式の例：\n",
    "チュートリアルの概要（どういうものか、ゴールは何か）\n",
    "これを選んだ理由\n",
    "コードリーディング・デバッグで学んだこと（一番難しかったところ、応用できそうなところ）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "・keras シンプルで使いやすい  \n",
    "・pytorch 使いづらいが拡張性が高い  \n",
    "・tensorflow  使いづら過ぎるが、使用率が高い  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}