{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e9f32fa171224d35b8f216d6a0a18bd8ade16596fd4c89539dbaf4c3a0355b6a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "### 2.1次元の畳み込みニューラルネットワークスクラッチ\n",
    "\n",
    "\n",
    "畳み込みニューラルネットワーク（CNN） のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "このSprintでは1次元の 畳み込み層 を作成し、畳み込みの基礎を理解することを目指します。次のSprintでは2次元畳み込み層とプーリング層を作成することで、一般的に画像に対して利用されるCNNを完成させます。\n",
    "\n",
    "クラスの名前はScratch1dCNNClassifierとしてください。クラスの構造などは前のSprintで作成したScratchDeepNeuralNetrowkClassifierを参考にしてください。\n",
    "\n",
    "1次元畳み込み層とは\n",
    "CNNでは画像に対しての2次元畳み込み層が定番ですが、ここでは理解しやすくするためにまずは1次元畳み込み層を実装します。1次元畳み込みは実用上は自然言語や波形データなどの 系列データ で使われることが多いです。\n",
    "\n",
    "畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまではフレームワークで一般的に用意されています。\n",
    "\n",
    "データセットの用意\n",
    "検証には引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。\n",
    "\n",
    "#### 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dia_matrix\n",
    "class SimpleConv1d:\n",
    "    def __init__(self, weight, baias):\n",
    "        self.optimizer = None\n",
    "\n",
    "        self.W = weight\n",
    "        self.B = baias\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        self.idx =None\n",
    "        self.X = None\n",
    "        pass\n",
    "    def output(self,X):\n",
    "        n_in = X.shape[1]\n",
    "        p = 0 #バディング\n",
    "        f = self.W.shape[0] #フィルタのサイズ\n",
    "        s = 1 #ストライドのサイズ\n",
    "        n_out = ((n_in + 2*p - f)/s)+1\n",
    "        return n_out\n",
    "    def forward(self, X):\n",
    "        #配列\n",
    "        self.a = X.copy()\n",
    "        idx1 = np.arange(self.W.shape[0])\n",
    "        idx2 = np.arange(self.W.shape[0]-1 ).reshape(-1, 1)\n",
    "        self.idx = idx1 + idx2\n",
    "        A = np.sum(X[self.idx] * self.W.T,axis=1) + self.B\n",
    "        return A\n",
    "    def backward(self, dX,dA):\n",
    "\n",
    "        dB = np.sum(dA,axis=0)\n",
    "        dW = np.sum(dA[:,np.newaxis] *dX[idx],axis=0)\n",
    "        #scipyを利用した\n",
    "        da = dA.reshape(-1,1)\n",
    "        data= np.repeat(da,dX.shape[0],axis=1)\n",
    "        offsets= np.arange(self.output(self.a))\n",
    "        d = dia_matrix((data,offsets),shape=(w.shape[0],x.shape[0])).toarray()\n",
    "        dx = np.sum(d * w[:,np.newaxis],axis=0)\n",
    "        # 更新\n",
    "        #self = self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        #print(\"dB\",layer.dB.shape)\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        return "
   ]
  },
  {
   "source": [
    "#### 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "$$\n",
    "N_{out} =  \\frac{N_{in}+2P-F}{S} + 1\\\\\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(X,p,f,s):\n",
    "    n_in = X.shape[0]\n",
    "    p = p #バディング\n",
    "    f = f #フィルタのサイズ\n",
    "    s = s #ストライドのサイズ\n",
    "    n_out = ((n_in + 2*p - f)/s)+1\n",
    "    return n_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # n_in = x.shape[1]\n",
    "    # p = 0 #バディング\n",
    "    # f = 3 #フィルタのサイズ\n",
    "    # s = 1 #ストライドのサイズ\n",
    "    # n_out = ((n_in + 2*p - f)/s)+1\n",
    "    # n_out"
   ]
  },
  {
   "source": [
    "#### 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "source": [
    "フォワードプロパゲーションをすると出力は次のようになります。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((4,), (3,), (1,))"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "x.shape,w.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([35, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2]\n[[0]\n [1]]\n[[0 1 2]\n [1 2 3]]\n[[1 2 3]\n [2 3 4]]\n[[ 3 10 21]\n [ 6 15 28]]\n[35 50]\n"
     ]
    }
   ],
   "source": [
    "#配列\n",
    "idx1 = np.arange(w.shape[0])\n",
    "print(idx1)\n",
    "idx2 = np.arange(w.shape[0]-1 ).reshape(-1, 1)\n",
    "print(idx2)\n",
    "idx = idx1 + idx2\n",
    "print(idx)\n",
    "print(x[idx])\n",
    "a = np.sum(x[idx] * w.T,axis=1) + b\n",
    "print(x[idx] * w.T)\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "sc1 = SimpleConv1d(w,b)\n",
    "sc1.forward(x)"
   ]
  },
  {
   "source": [
    "次にバックプロパゲーションを考えます。誤差は次のようであったとします。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "delta_a = np.array([10, 20])\n",
    "delta_a.shape"
   ]
  },
  {
   "source": [
    "バックプロパゲーションをすると次のような値になります。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "dB = np.sum(delta_a,axis=0)\n",
    "dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 50,  80, 110])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "dW = np.sum(delta_a[:,np.newaxis] *x[idx],axis=0)\n",
    "dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #配列\n",
    "# jdx = np.arange(x.shape[0])\n",
    "# print(jdx)\n",
    "# sdx = np.arange(w.shape[0] ).reshape(-1, 1)\n",
    "# print(sdx)\n",
    "# j_s = jdx - sdx\n",
    "# print(j_s)\n",
    "# for i in j_s:\n",
    "#     if i < 0 or i >1:\n",
    "#         j_s = 0\n",
    "#     else:\n",
    "#         dx = delta_a[i]\n",
    "# #思いつかﾂﾞ断念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 30., 110., 170., 140.])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "dx = np.zeros(x.shape[0])\n",
    "for j in range(x.shape[0]):\n",
    "    for s in range(w.shape[0]):\n",
    "        if j-s < 0 or j-s >1:\n",
    "            dx[j] += 0\n",
    "        else:\n",
    "            dx[j] += delta_a[j - s] * w[s]\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[10]\n [20]]\n[[10 10 10 10]\n [20 20 20 20]]\n[0 1]\n[[10 20  0  0]\n [ 0 10 20  0]\n [ 0  0 10 20]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import dia_matrix\n",
    "#scipyを利用した\n",
    "da = delta_a.reshape(-1,1)\n",
    "print(da)\n",
    "data= np.repeat(da,x.shape[0],axis=1)\n",
    "print(data)\n",
    "offsets= np.arange(0,int(output(x,0,3,1)))\n",
    "print(offsets)\n",
    "da = dia_matrix((data,offsets),shape=(w.shape[0],x.shape[0])).toarray()\n",
    "print(da)\n",
    "# 更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 30, 110, 170, 140])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "dx = np.sum(da * w[:,np.newaxis],axis=0)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc1 = SimpleConv1d(delta_w,delta_b)\n",
    "# sc1.backward(delta_x,delta_a)"
   ]
  },
  {
   "source": [
    "実装上の工夫\n",
    "畳み込みを実装する場合は、まずはfor文を重ねていく形で構いません。しかし、できるだけ計算は効率化させたいため、以下の式を一度に計算する方法を考えることにします。\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$\n",
    "バイアス項は単純な足し算のため、重みの部分を見ます。\n",
    "$$\n",
    "\\sum_{s=0}^{F-1}x_{(i+s)}w_s\n",
    "$$\n",
    "これは、xの一部を取り出した配列とwの配列の内積です。具体的な状況を考えると、以下のようなコードで計算できます。この例では流れを分かりやすくするために、各要素同士でアダマール積を計算してから合計を計算しています。これは結果的に内積と同様です。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "a = np.empty((2, 3))\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "\n",
    "a = a.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([34., 49.])"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "source": [
    "ndarrayは配列を使ったインデックス指定ができることを利用した方法です。\n",
    "\n",
    "また、二次元配列を使えば一次元配列から二次元配列が取り出せます。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 2 3]\n [2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])"
   ]
  },
  {
   "source": [
    "このこととブロードキャストなどをうまく組み合わせることで、一度にまとめて計算することも可能です。\n",
    "\n",
    "畳み込みの計算方法に正解はないので、自分なりに効率化していってください。\n",
    "\n",
    "《参考》\n",
    "\n",
    "以下のページのInteger array indexingの部分がこの方法についての記述です。\n",
    "[Indexing — NumPy v1.17 Manual](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。\n",
    "\n",
    "例えば以下のようなx, w, bがあった場合は、"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "source": [
    "出力は次のようになります。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。"
   ]
  },
  {
   "source": [
    "入力が2チャンネル、出力が3チャンネルの例です。計算グラフを書いた上で、バックプロパゲーションも手計算で考えてみましょう。計算グラフの中には和と積しか登場しないので、微分を新たに考える必要はありません。\n",
    "\n",
    "《補足》\n",
    "\n",
    "チャンネル数を加える場合、配列をどういう順番にするかという問題があります。(バッチサイズ、チャンネル数、特徴量数)または(バッチサイズ、特徴量数、チャンネル数)が一般的で、ライブラリによって順番は異なっています。（切り替えて使用できるものもあります）\n",
    "\n",
    "今回のスクラッチでは自身の実装上どちらが効率的かを考えて選んでください。上記の例ではバッチサイズは考えておらず、(チャンネル数、特徴量数)です。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 3, 4, 5]])"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 863
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 2, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 862
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output2(X,p,f,s):\n",
    "    n_in = X.shape[1]\n",
    "    p = p #バディング\n",
    "    f = f #フィルタのサイズ\n",
    "    s = s #ストライドのサイズ\n",
    "    n_out = ((n_in + 2*p - f)/s)+1\n",
    "    return n_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "#o　出力サイズ\n",
    "o = int(output2(x,0,w.shape[-1],1))\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n2 4\n3 2 3\n"
     ]
    }
   ],
   "source": [
    "#o　出力サイズ\n",
    "o = int(output2(x,0,w.shape[-1],1))\n",
    "print(o)\n",
    "#ninチャンネル  , i　特徴量\n",
    "nin, i = x.shape\n",
    "print(nin,i)\n",
    "#oc出力チャンネル , cチャンネル数 , fフィルタサイズ\n",
    "oc, c, f = w.shape\n",
    "print(oc,c,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "#c * f \n",
    "idx_arr = np.arange(c*f).reshape(c,f)\n",
    "idx_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.zeros((oc,o))\n",
    "# for oc in range(oc):\n",
    "#     for ni in range(nin):\n",
    "#         for o in range(o):\n",
    "#             A[oc , o] += np.sum(x[ni, o:o+f] * w[oc, ni, :])\n",
    "#             print(A)\n",
    "# print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 2, 3)\n[[[1 2 3]\n  [2 3 4]]\n\n [[2 3 4]\n  [3 4 5]]]\n(2, 3)\na (3, 2)\n(2, 3)\na (3, 2)\n()\n[[31. 43.]\n [ 0.  0.]\n [ 0.  0.]]\n(2, 3)\na (3, 2)\n(2, 3)\na (3, 2)\n()\n[[31. 43.]\n [32. 44.]\n [ 0.  0.]]\n(2, 3)\na (3, 2)\n(2, 3)\na (3, 2)\n()\n[[31. 43.]\n [32. 44.]\n [33. 45.]]\n"
     ]
    }
   ],
   "source": [
    "#フォワード\n",
    "idx1 = np.arange(w.shape[-1])\n",
    "\n",
    "idx2 = np.arange(w.shape[-1]-1 ).reshape(-1, 1)\n",
    "\n",
    "idx = idx1 + idx2\n",
    "\n",
    "print(x[:,idx].shape)\n",
    "a1 = x[:,idx]\n",
    "a2 = w\n",
    "print(a1)\n",
    "a= np.zeros((f,o))\n",
    "for i in range(f):\n",
    "    for j in range(o):\n",
    "        x_in = a1[j]\n",
    "        print(x_in.shape)\n",
    "        a[i][j] = np.sum(x_in @ w[i][j])\n",
    "        print('a',a.shape)\n",
    "    print(b[i].shape)\n",
    "    a[i] += a[i] + b[i]\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 2, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4],\n",
       "        [3, 4, 5]]])"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "output2(x,0,w.shape[-1],1) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([74., 76., 78.])"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "#バックプロパゲーション\n",
    "db = np.sum(a,axis=1)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 2, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 409
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4],\n",
       "        [3, 4, 5]]])"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 408
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[31., 43.],\n",
       "       [32., 44.],\n",
       "       [33., 45.]])"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 407
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "aa1 = a1.flatten()\n",
    "len(aa1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([31., 43., 32., 44., 33., 45.])"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "aa = a.flatten()\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "metadata": {},
     "execution_count": 406
    }
   ],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[31.],\n",
       "       [43.],\n",
       "       [32.],\n",
       "       [44.],\n",
       "       [33.],\n",
       "       [45.]])"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "aaa = aa[:,np.newaxis]\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 405
    }
   ],
   "source": [
    "aaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 31.,  62.,  93.,  62.,  93., 124.,  62.,  93., 124.,  93., 124.,\n",
       "        155.],\n",
       "       [ 43.,  86., 129.,  86., 129., 172.,  86., 129., 172., 129., 172.,\n",
       "        215.],\n",
       "       [ 32.,  64.,  96.,  64.,  96., 128.,  64.,  96., 128.,  96., 128.,\n",
       "        160.],\n",
       "       [ 44.,  88., 132.,  88., 132., 176.,  88., 132., 176., 132., 176.,\n",
       "        220.],\n",
       "       [ 33.,  66.,  99.,  66.,  99., 132.,  66.,  99., 132.,  99., 132.,\n",
       "        165.],\n",
       "       [ 45.,  90., 135.,  90., 135., 180.,  90., 135., 180., 135., 180.,\n",
       "        225.]])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "aaaa = aaa * aa1\n",
    "aaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 404
    }
   ],
   "source": [
    "aaaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 31.,  62.,  93.,  62.],\n",
       "       [ 93., 124.,  62.,  93.],\n",
       "       [124.,  93., 124., 155.],\n",
       "       [ 43.,  86., 129.,  86.],\n",
       "       [129., 172.,  86., 129.],\n",
       "       [172., 129., 172., 215.],\n",
       "       [ 32.,  64.,  96.,  64.],\n",
       "       [ 96., 128.,  64.,  96.],\n",
       "       [128.,  96., 128., 160.],\n",
       "       [ 44.,  88., 132.,  88.],\n",
       "       [132., 176.,  88., 132.],\n",
       "       [176., 132., 176., 220.],\n",
       "       [ 33.,  66.,  99.,  66.],\n",
       "       [ 99., 132.,  66.,  99.],\n",
       "       [132.,  99., 132., 165.],\n",
       "       [ 45.,  90., 135.,  90.],\n",
       "       [135., 180.,  90., 135.],\n",
       "       [180., 135., 180., 225.]])"
      ]
     },
     "metadata": {},
     "execution_count": 412
    }
   ],
   "source": [
    "b=  aaaa.reshape((18,4))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[248., 372., 496.],\n",
       "        [344., 516., 688.]],\n",
       "\n",
       "       [[256., 384., 512.],\n",
       "        [352., 528., 704.]],\n",
       "\n",
       "       [[264., 396., 528.],\n",
       "        [360., 540., 720.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 413
    }
   ],
   "source": [
    "np.sum(b,axis=1).reshape(3,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "b = np.zeros((oc*c*f))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[31.],\n",
       "        [43.]],\n",
       "\n",
       "       [[32.],\n",
       "        [44.]],\n",
       "\n",
       "       [[33.],\n",
       "        [45.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "a[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1.],\n",
       "        [1.],\n",
       "        [1.]],\n",
       "\n",
       "       [[1.],\n",
       "        [1.],\n",
       "        [1.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "w[0][:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[1, 2, 3],\n",
       "        [2, 3, 4]],\n",
       "\n",
       "       [[2, 3, 4],\n",
       "        [3, 4, 5]]])"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[31. 43.  0.  0.]\n [ 0. 31. 43.  0.]\n [ 0.  0. 31. 43.]]\n[[31. 74. 74. 43.]\n [31. 74. 74. 43.]]\n[[32. 44.  0.  0.]\n [ 0. 32. 44.  0.]\n [ 0.  0. 32. 44.]]\n[[ 63. 150. 150.  87.]\n [ 63. 150. 150.  87.]]\n[[33. 45.  0.  0.]\n [ 0. 33. 45.  0.]\n [ 0.  0. 33. 45.]]\n[[ 96. 228. 228. 132.]\n [ 96. 228. 228. 132.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import dia_matrix\n",
    "#scipyを利用した\n",
    "dd = 0\n",
    "for i in range(a.shape[0]):\n",
    "    da = a[:,:,np.newaxis]\n",
    "    #print(da)\n",
    "    data= np.repeat(da[i],x.shape[1],axis=1)\n",
    "    #print(data)\n",
    "    offsets= np.arange(int(output2(x,0,3,1)))\n",
    "    #print(offsets)\n",
    "    da = dia_matrix((data,offsets),shape=(w.shape[-1],x.shape[1])).toarray()\n",
    "    print(da)\n",
    "    # 更新\n",
    "    dd += np.sum(da * w[i][:,:,np.newaxis],axis=1)\n",
    "    print(dd)\n",
    "    "
   ]
  },
  {
   "source": [
    "#### 【問題5】（アドバンス課題）パディングの実装\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "最も単純なパディングは全て0で埋める ゼロパディング であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。\n",
    "\n",
    "[numpy.pad — NumPy v1.17 Manual](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dia_matrix\n",
    "class Conv1d:\n",
    "    def __init__(self,ch, f_num, f_size, initializer,optimizer):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.W = initializer.W(f_num=f_num,f_size=f_size,ch=ch)\n",
    "        self.B = initializer.B(f_num)\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        self.idx =None\n",
    "        self.X = None\n",
    "        self.A = None\n",
    "        pass\n",
    "\n",
    "    def output(self,X,p,f,s):\n",
    "        self.x_in = X.shape[-1]\n",
    "        n_out = int(((self.x_in + 2*p - f)/s)+1)\n",
    "        return n_out\n",
    "\n",
    "    def forward(self, X):\n",
    "        #print(X.shape)\n",
    "        self.X = X\n",
    "        #shape\n",
    "        i_ch,featu = self.X.shape\n",
    "        o_ch,i_ch,f_size = self.W.shape\n",
    "        self.o_size = self.output(X,0,f_size,1)\n",
    "        A = np.zeros((o_ch,self.o_size))\n",
    "\n",
    "        idx1 = np.arange(f_size)\n",
    "        idx2 = np.arange(f_size-1 ).reshape(-1, 1)\n",
    "        idx = idx1 + idx2\n",
    "        self.xs = X[:,idx]\n",
    "        # for os in range(self.o_size):\n",
    "        #     for oc in range(o_ch):\n",
    "        #         x_in = self.xs[oc]\n",
    "        #         print(\"x_in\",x_in.shape)\n",
    "        #         A[os,oc] = np.sum(x_in @ self.W[os,oc]) \n",
    "        #     A[os] += A[os] + self.B[os]\n",
    "        #     print(A.shape)\n",
    "\n",
    "        for oc in range(o_ch):\n",
    "            for ic in range(i_ch):\n",
    "                for os in range(self.o_size):\n",
    "                    A[oc , os] += np.sum(self.X[ic, os:os+f_size] * self.W[oc, ic, :])\n",
    "        A += self.B.reshape(-1,1)\n",
    "        #print(A.shape)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        i_ch,featu = self.X.shape\n",
    "        o_ch,i_ch,f_size = self.W.shape\n",
    "        #バックプロパゲーション\n",
    "        #bias\n",
    "        self.dB = np.sum(dA,axis=1)\n",
    "\n",
    "        # #weight\n",
    "        # x_flat = self.xs.flatten()\n",
    "        # a_flat = dA.flatten()\n",
    "        # print('a_flat',a_flat.shape)\n",
    "        # x_to = x_flat[:,np.newaxis]\n",
    "        # print('x_to',x_to.shape)\n",
    "        # ax = x_to * a_flat\n",
    "        # print('ax',ax.shape)\n",
    "        # w_flat=  ax.reshape((self.o_ch*self.i_ch*self.f_size,self.featu))\n",
    "        # self.dW = np.sum(w_flat,axis=1).reshape(self.o_ch,self.i_ch,self.f_size)\n",
    "\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        for oc in range(o_ch):\n",
    "            for ic in range(i_ch):\n",
    "                for f in range(f_size):\n",
    "                    for os in range(self.o_size):\n",
    "                        self.dW[oc,ic,f] += dA[ic,os] * self.X[ic,f + os]\n",
    "        #print('dB',self.dB.shape)\n",
    "        #print('dW',self.dW.shape)\n",
    "        #backpropa\n",
    "        dX = 0\n",
    "        for i in range(o_ch):\n",
    "            da = dA[:,:,np.newaxis]\n",
    "            data= np.repeat(da[i],i_ch,axis=1)\n",
    "            offsets= np.arange(self.o_size)\n",
    "            #print(offsets)\n",
    "            da = dia_matrix((data,offsets),shape=(f_size,i_ch)).toarray()\n",
    "            dX += np.sum(da * self.W[i][:,:,np.newaxis],axis=1)\n",
    "\n",
    "         # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X.copy()\n",
    "        #print('X',X.shape)\n",
    "        #print('W',self.W.shape)\n",
    "        A= X @ self.W\n",
    "        A = A + self.B\n",
    "        return  A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "\n",
    "        self.dB = np.sum(dA,axis=0) \n",
    "        self.dW = self.X.T @ dA\n",
    "        dZ = dA @ self.W.T #次の層で使う\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def W(self, n_nodes1=None, n_nodes2=None,f_num=None,f_size=None,ch=None):\n",
    "        if f_num is not None:\n",
    "            W = np.random.randn(f_num,ch,f_size)* np.sqrt(2/f_num)\n",
    "        else:\n",
    "            W = np.random.randn(n_nodes1,n_nodes2) * np.sqrt(2/n_nodes1)\n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = np.random.randn(n_nodes2)     \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.hb = 0.1\n",
    "        self.hw = 0.1\n",
    "    def update(self, layer):\n",
    "        self.hb +=  (layer.dB) **2 \n",
    "        self.hw += (layer.dW)**2\n",
    "        layer.B -= self.lr / np.square(self.hb)*layer.dB\n",
    "        layer.W -= self.lr / np.square(self.hw)*layer.dW\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.A = None\n",
    "    def forward(self, X):\n",
    "        self.A = np.copy(X)\n",
    "        return np.maximum(0,X)\n",
    "    def backward(self, X):\n",
    "        return np.where(self.A>0,X,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax関数\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.b = None\n",
    "    def forward(self,x):\n",
    "        self.b = np.exp(x-np.max(x))/np.sum(np.exp(x-np.max(x)), axis =1, keepdims =True)\n",
    "        return self.b\n",
    "    def backward(self,t):\n",
    "        self.batch = t.shape[0]\n",
    "        loss = -1/self.batch * np.sum(np.sum(t*np.log(self.b),axis=0))\n",
    "        dx = (self.b - t) /self.batch\n",
    "        return dx, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "class GetMiniBatch:\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ハイパボリックタンジェント\n",
    "class Tanh():\n",
    "    def __init__(self):\n",
    "        self.A = None\n",
    "    def forward(self,X):\n",
    "        self.A = np.tanh(X)\n",
    "        return self.A\n",
    "    def backward(self,X):\n",
    "        return X * (1 - (np.tanh(self.A))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flat():\n",
    "    def __init__(self):\n",
    "        self.X_shape = None\n",
    "    def forward(self,X):\n",
    "        x1d = X.reshape(X.shape[0],-1)\n",
    "        self.X_shape = X.shape\n",
    "        return x1d\n",
    "    def backward(self,X):\n",
    "        X = X.reshape(self.X_shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratchch1dCNNNeuralNetrowkClassifier():    \n",
    "    def __init__(self,lr=0.01,sigma=0.01,n_node1=200,n_node2=100,n_output=10,verbose=True,epoch=5,batch_size=10,activation=\"tanh\",initial=\"simple\",optimizer=\"sgd\",f_num=10,f_size=100):\n",
    "        # self.sigma : ガウス分布の標準偏差\n",
    "        # self.lr : 学習率\n",
    "        # self.n_nodes1 : 1層目のノード数\n",
    "        # self.n_nodes2 : 2層目のノード数\n",
    "        # self.n_output : 出力層のノード数\n",
    "        self.lr = lr\n",
    "        self.sigma = sigma\n",
    "        self.n_nodes1 = n_node1\n",
    "        self.n_nodes2 = n_node2\n",
    "        self.n_output = n_output\n",
    "        self.epoch = epoch\n",
    "        self.verbose = verbose\n",
    "        self.batch = batch_size\n",
    "        self.activation = activation\n",
    "        self.initial = initial\n",
    "        self.optimizer = optimizer\n",
    "        self.f_num = f_num\n",
    "        self.f_size = f_size\n",
    "\n",
    "    def fit(self,X,y,X_val=None,y_val=None):\n",
    "        get_mini_batch = GetMiniBatch(X, y, self.batch)\n",
    "        #val\n",
    "        if X_val is not None:      \n",
    "            test_mini_batch = GetMiniBatch(X_val, y_val) \n",
    "\n",
    "        self.inch = self.batch\n",
    "        self.n_features = X.shape[1]\n",
    "\n",
    "        if self.optimizer == \"sgd\":\n",
    "            optimizer1 = SGD(self.lr)\n",
    "            optimizer2 = SGD(self.lr)\n",
    "            optimizer3 = SGD(self.lr)\n",
    "        elif self.optimizer == \"ada\":\n",
    "            optimizer1 = AdaGrad(self.lr)\n",
    "            optimizer2 = AdaGrad(self.lr)\n",
    "            optimizer3 = AdaGrad(self.lr)\n",
    "            optimizer4 = AdaGrad(self.lr)\n",
    "\n",
    "        if self.activation == \"tanh\":\n",
    "            self.activation1 = Tanh()\n",
    "            self.activation2= Tanh()\n",
    "            self.activation3 = Tanh()\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            self.activation1 = Sigmoid()\n",
    "            self.activation2= Sigmoid()\n",
    "        elif self.activation == \"relu\":\n",
    "            self.activation1 = ReLU()\n",
    "            self.activation2= ReLU()\n",
    "            self.activation3= ReLU()\n",
    "\n",
    "        if self.initial == \"simple\":\n",
    "            initial = SimpleInitializer(self.sigma)\n",
    "        elif self.initial == \"xavier\":\n",
    "            initial = XavierInitializer()\n",
    "        elif self.initial == \"he\":\n",
    "            initial1 = HeInitializer()\n",
    "            initial2 = HeInitializer()          \n",
    "            initial3 = HeInitializer()\n",
    "            initial4 = HeInitializer()           \n",
    "        #1\n",
    "        self.CON1 = Conv1d(self.inch,self.f_num,self.f_size,initial1,optimizer1)\n",
    "\n",
    "        self.flat = Flat()\n",
    "        out = int(X.shape[1] - (self.f_size -1))\n",
    "        self.FC1 = FC(out, self.n_nodes1, initial2, optimizer2)\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, initial3, optimizer3)\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, initial4, optimizer4)\n",
    "        \n",
    "        self.activation4 = Softmax()\n",
    "\n",
    "        self.epo_lis = []\n",
    "        self.loss_lis = []\n",
    "        self.val_lis = []\n",
    "        for i in range(self.epoch):\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                Y = (mini_y_train.reshape(-1,1)==np.arange(10)).astype(np.float64)\n",
    "                self._forward(mini_X_train)\n",
    "\n",
    "                dA4, loss = self.activation4.backward(Y) \n",
    "                #print(loss)# 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                #print(\"dA3\",dA3.shape)\n",
    "                dZ4 = self.FC3.backward(dA4)\n",
    "                #print(\"dZ4\",dZ4.shape )\n",
    "                dA3 = self.activation3.backward(dZ4)\n",
    "                #print('dA3',dA3)\n",
    "                dZ3 = self.FC2.backward(dA3)\n",
    "                #print('dZ3',dZ3)\n",
    "                dA2 = self.activation2.backward(dZ3)\n",
    "                #print('dA2',dA2)\n",
    "                dZ2 = self.FC1.backward(dA2) \n",
    "                #print('dZ2',dZ2)\n",
    "                dF = self.flat.backward(dZ2)\n",
    "                #print('dF',dF)\n",
    "                dA1 = self.activation1.backward(dF)\n",
    "                #print('dA1',dA1)\n",
    "                dZ1 = self.CON1.backward(dA1)\n",
    "                #print('dZ1',dZ1)\n",
    "            self.loss_lis.append(loss)\n",
    "            #検証\n",
    "            if X_val is not None:\n",
    "                for mini_X_val,mini_y_val in test_mini_batch:\n",
    "                    y_val_one = (mini_y_val.reshape(-1,1)==np.arange(10)).astype(np.float64)\n",
    "                    y_pre = np.argmax(self._forward(mini_X_val)  ,axis=1)\n",
    "                    accura = accuracy_score(mini_y_val,y_pre)\n",
    "                self.val_lis.append(self.activation4.backward(y_val_one)[1])\n",
    "            self.epo_lis.append(i+1)\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            if self.verbose:\n",
    "                print( \"epoch\",i+1,\"loss{:.3f}\".format(loss),\"accuracy:\",accura,\"ini\",self.initial,\"activation\",self.activation,\"optimizer\",self.optimizer)\n",
    "            pass\n",
    "    def _forward(self,X):\n",
    "        A0 = self.CON1.forward(X)\n",
    "        #print(A0.shape)\n",
    "        Z0 = self.activation1.forward(A0)\n",
    "        #print('Z0',Z0.shape)\n",
    "        F = self.flat.forward(Z0)\n",
    "        #print('F',F.shape)\n",
    "        A1 = self.FC1.forward(F)\n",
    "        #print('A1',A1.shape)\n",
    "        Z1 = self.activation2.forward(A1)\n",
    "        #print(Z1.shape)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        #print('A2',A2.shape)\n",
    "        Z2 = self.activation3.forward(A2)\n",
    "        #print('Z2',Z2.shape)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        #print(\"A3\",A3.shape)\n",
    "        Z3 = self.activation4.forward(A3)        \n",
    "        #print('Z3',Z3.shape)\n",
    "        return Z3\n",
    "    def predict(self,X):\n",
    "\n",
    "        return np.argmax(self._forward(X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前処理\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 loss4.418 accuracy: 0.1 ini he activation tanh optimizer ada\n",
      "epoch 2 loss3.589 accuracy: 0.1 ini he activation tanh optimizer ada\n",
      "epoch 3 loss1.006 accuracy: 0.0 ini he activation tanh optimizer ada\n",
      "epoch 4 loss0.455 accuracy: 0.0 ini he activation tanh optimizer ada\n",
      "epoch 5 loss0.054 accuracy: 0.1 ini he activation tanh optimizer ada\n"
     ]
    }
   ],
   "source": [
    "cnn = Scratchch1dCNNNeuralNetrowkClassifier(epoch=5,activation=\"tanh\",initial=\"he\",optimizer=\"ada\")\n",
    "\n",
    "cnn.fit(X_train[0:50],y_train[0:50],X_val[0:20],y_val[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9c50cbed00>]"
      ]
     },
     "metadata": {},
     "execution_count": 910
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 362.5625 248.518125\" width=\"362.5625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-13T23:34:43.882212</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 362.5625 248.518125 \nL 362.5625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 20.5625 224.64 \nL 355.3625 224.64 \nL 355.3625 7.2 \nL 20.5625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0e7e5188e7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.780682\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1.0 -->\n      <g transform=\"translate(27.829119 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"73.826136\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.5 -->\n      <g transform=\"translate(65.874574 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"111.871591\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2.0 -->\n      <g transform=\"translate(103.920028 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"149.917045\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.5 -->\n      <g transform=\"translate(141.965483 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"187.9625\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 3.0 -->\n      <g transform=\"translate(180.010938 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"226.007955\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.5 -->\n      <g transform=\"translate(218.056392 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"264.053409\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 4.0 -->\n      <g transform=\"translate(256.101847 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.098864\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4.5 -->\n      <g transform=\"translate(294.147301 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"340.144318\" xlink:href=\"#m0e7e5188e7\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5.0 -->\n      <g transform=\"translate(332.192756 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4af9a70701\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m4af9a70701\" y=\"216.039097\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0 -->\n      <g transform=\"translate(7.2 219.838316)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m4af9a70701\" y=\"168.521667\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2 -->\n      <g transform=\"translate(7.2 172.320886)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m4af9a70701\" y=\"121.004236\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 4 -->\n      <g transform=\"translate(7.2 124.803455)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m4af9a70701\" y=\"73.486806\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 6 -->\n      <g transform=\"translate(7.2 77.286024)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m4af9a70701\" y=\"25.969375\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 8 -->\n      <g transform=\"translate(7.2 29.768594)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p9eeb4725f8)\" d=\"M 35.780682 111.078123 \nL 111.871591 130.770495 \nL 187.9625 192.144294 \nL 264.053409 205.225288 \nL 340.144318 214.756364 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p9eeb4725f8)\" d=\"M 35.780682 17.083636 \nL 111.871591 131.69267 \nL 187.9625 104.642535 \nL 264.053409 93.286623 \nL 340.144318 92.485796 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 20.5625 224.64 \nL 20.5625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 355.3625 224.64 \nL 355.3625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 20.5625 224.64 \nL 355.3625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 20.5625 7.2 \nL 355.3625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9eeb4725f8\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"20.5625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(cnn.epo_lis,cnn.loss_lis)\n",
    "plt.plot(cnn.epo_lis,cnn.val_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}